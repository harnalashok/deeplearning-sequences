{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_prices.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gH4oS59n5xWhVQh2AOkUcxZT8OKxBAsC",
      "authorship_tag": "ABX9TyO3jLZuAUdfwz1Z1IPS6kb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning-sequences/blob/main/stock_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKoXVvjxdm5U",
        "outputId": "f52bb74a-9b6f-4618-c862-6b61eae747d7"
      },
      "source": [
        "# 0.0 Install attention\n",
        "! pip install attention"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting attention\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/3f/d8b19195a2f5827dcbf0ee6d7e6fe4352f42dcc60693bdb1e431440c8b59/attention-4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.7/dist-packages (from attention) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from attention) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.34.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.32.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (0.4.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1->attention) (1.5.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1->attention) (4.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1->attention) (3.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1->attention) (3.1.1)\n",
            "Installing collected packages: attention\n",
            "Successfully installed attention-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1utrffzY_qE-"
      },
      "source": [
        "# 1.0 Usual libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1.1 tensorflow related libraries\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from attention import Attention"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-xguyMfq6-"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc5Jm-1Y8dmh"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab_data_files/tatamotors/tatamotors.csv\"\n",
        "f = open(path)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuamblv0_nTr"
      },
      "source": [
        "lines = f.read()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GW5eeb15Ey1Q",
        "outputId": "a3bd0dff-daf4-4875-b469-dc977b129f49"
      },
      "source": [
        "lines[:4]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'date'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFQwcc_AAfR"
      },
      "source": [
        "lines = lines.split(\"\\n\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-BJVHijEfyq",
        "outputId": "55c52285-0ab0-4650-e310-ba5e25ce1b6e"
      },
      "source": [
        "lines[:4]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['date,symbol,series,prevclose,open,high,low,last,close,vwap,volume,turnover',\n",
              " '03-01-2000,TELCO,EQ,201.6,207.4,217.25,207.4,217,216.75,214.28,676126,1.44878E+13',\n",
              " '04-01-2000,TELCO,EQ,216.75,217,219,206,211.9,208.2,209.5,679215,1.42296E+13',\n",
              " '05-01-2000,TELCO,EQ,208.2,194,217.8,194,213.1,213.25,210.33,1120951,2.35768E+13']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp6UfqKeACDk",
        "outputId": "bd8acf97-7b11-4388-c755-af6f1ba01644"
      },
      "source": [
        "header = lines[0]\n",
        "header = header.split(',')\n",
        "print(header)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['date', 'symbol', 'series', 'prevclose', 'open', 'high', 'low', 'last', 'close', 'vwap', 'volume', 'turnover']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJRxgB9wCCTA"
      },
      "source": [
        "lines = lines[1:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fClm6rKvCIMk",
        "outputId": "2c081462-db70-463c-bb0b-f57cefb197d1"
      },
      "source": [
        "lines[:4]\n",
        "len(lines)   # 5307"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['03-01-2000,TELCO,EQ,201.6,207.4,217.25,207.4,217,216.75,214.28,676126,1.44878E+13',\n",
              " '04-01-2000,TELCO,EQ,216.75,217,219,206,211.9,208.2,209.5,679215,1.42296E+13',\n",
              " '05-01-2000,TELCO,EQ,208.2,194,217.8,194,213.1,213.25,210.33,1120951,2.35768E+13',\n",
              " '06-01-2000,TELCO,EQ,213.25,215,229.9,215,222,222.1,225.29,1968998,4.43593E+13']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5307"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhv_OgT0gip9"
      },
      "source": [
        "np.zeros([12,12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkyaMs4if6od",
        "outputId": "d8eda98c-e6bf-4f6e-b9ae-248d495aa6aa"
      },
      "source": [
        "data = np.zeros([len(lines), len(header)-3])\n",
        "data.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5307, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqV0TwANRZNJ"
      },
      "source": [
        " for i, j in enumerate(lines):\n",
        "   j = j.split(',')\n",
        "   #print(j[3:])\n",
        "   #break;\n",
        "   t = np.array(j[3:])\n",
        "   data[i] = t\n",
        "   break\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6--chpZ3kjFG"
      },
      "source": [
        "for i in range(len(lines)-1):\n",
        "  j = lines[i].split(',')\n",
        "  t = np.array(j[3:])\n",
        "  data[i] = t"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YT1BjARkRuW",
        "outputId": "9a08bc86-3def-4c4f-dbe4-4771ee51b47c"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5307, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZrbZLpP5bQ8"
      },
      "source": [
        "data = pd.read_csv(path)\n",
        "data = data.loc[:,['prevclose', 'open', 'high', 'low', 'last', 'vwap', 'volume', 'turnover', 'close']]\n",
        "data = data.values"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvhRR7yn-XZl",
        "outputId": "df23f3e2-2cc4-4d17-c42a-3f7401a41aa9"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5306, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t71S4TFgDtSJ"
      },
      "source": [
        "# 3.1 Global mean of each one of all eight columns\n",
        "mean = data.mean(axis = 0)\n",
        "data -= mean\n"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoEPfVwyD3Mb"
      },
      "source": [
        "# Std of each one of eight columns\n",
        "std = data.std(axis = 0)\n",
        "data /= std"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJktavSz75pJ",
        "outputId": "ad8fdcea-7ae0-4bee-e2f6-a57d2b6ece37"
      },
      "source": [
        "np.zeros(3)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFBs8qLDk5Wx"
      },
      "source": [
        "def train_gen(time_steps, batches, min_index,max_index, ahead, data):\n",
        "  while 1:\n",
        "    dx = np.zeros([batches,time_steps,data.shape[-1]])\n",
        "    dy = np.zeros(batches)\n",
        "    for i in range(batches):\n",
        "      start = np.random.randint(min_index,max_index)\n",
        "      #print(start)\n",
        "      df = data[start:start+time_steps, :]\n",
        "      #print(df.shape)\n",
        "      dx[i,:,:] = df\n",
        "      dy[i] = data[start+time_steps+1,8 ]\n",
        "    yield dx, dy\n",
        "  \n"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aflYn7avqwpU"
      },
      "source": [
        "time_steps = 70\n",
        "min_index = 0\n",
        "max_index = 4000\n",
        "ahead = 1\n",
        "batches = 32\n",
        "data = data"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUn8ms4X8SNb"
      },
      "source": [
        "t = train_gen(time_steps, batches, min_index,max_index, ahead, data)"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlS8wtko8r9z"
      },
      "source": [
        "X,y = next(t)"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvEvSLaJ-u9A",
        "outputId": "0953fc5b-6d90-4287-deac-8485c33a1fb8"
      },
      "source": [
        "X.shape\n",
        "y.shape"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 70, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9XyMpUHRSL"
      },
      "source": [
        "time_steps = 70\n",
        "min_index = 4000\n",
        "max_index = 5000\n",
        "ahead = 1\n",
        "batches = 32\n",
        "data = data"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCific_YHb9g"
      },
      "source": [
        "v = train_gen(time_steps, batches, min_index,max_index, ahead, data)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRHVx-JDrPSo"
      },
      "source": [
        "# 4.0 Define the model.\n",
        "input_dim = X.shape[-1]\n",
        "model_input = Input(shape=(time_steps, input_dim))\n",
        "x = LSTM(70, return_sequences=True)(model_input)\n",
        "x = LSTM(70, return_sequences= True)(x)\n",
        "x = Attention(32)(x)\n",
        "x = Dense(16)(x)\n",
        "x = Dense(1)(x)\n",
        "model = Model(model_input, x)"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0QvDBohuHuq",
        "outputId": "0bd6fdbd-cfe1-4cbc-be6d-7956a5eb4d8f"
      },
      "source": [
        "# 4.1 Compile and print model summary\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "print(model.summary())"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 70, 9)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  (None, 70, 70)       22400       input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  (None, 70, 70)       39480       lstm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last_hidden_state (Lambda)      (None, 70)           0           lstm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_score_vec (Dense)     (None, 70, 70)       4900        lstm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_score (Dot)           (None, 70)           0           last_hidden_state[0][0]          \n",
            "                                                                 attention_score_vec[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "attention_weight (Activation)   (None, 70)           0           attention_score[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "context_vector (Dot)            (None, 70)           0           lstm_14[0][0]                    \n",
            "                                                                 attention_weight[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_output (Concatenate)  (None, 140)          0           context_vector[0][0]             \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "attention_vector (Dense)        (None, 128)          17920       attention_output[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 16)           2064        attention_vector[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1)            17          dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 86,781\n",
            "Trainable params: 86,781\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJg3s8GuB_17",
        "outputId": "a9cd5c28-b125-451d-d7eb-35e02f70c320"
      },
      "source": [
        "H = model.fit(\n",
        "              t,\n",
        "              steps_per_epoch= 60,\n",
        "              validation_data = v,\n",
        "              validation_steps = 10,\n",
        "              epochs= 100)"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 9s 100ms/step - loss: 0.0946 - val_loss: 0.0305\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0163 - val_loss: 0.0142\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0176 - val_loss: 0.0351\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0146 - val_loss: 0.0129\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0196 - val_loss: 0.0141\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0172 - val_loss: 0.0093\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0099 - val_loss: 0.0081\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0083 - val_loss: 0.0104\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0099 - val_loss: 0.0062\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0106 - val_loss: 0.0067\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0081 - val_loss: 0.0040\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0089 - val_loss: 0.0089\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0067 - val_loss: 0.0082\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0077 - val_loss: 0.0043\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0134 - val_loss: 0.0041\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0118 - val_loss: 0.0083\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0103 - val_loss: 0.0086\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0072 - val_loss: 0.0048\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0117 - val_loss: 0.0043\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0070 - val_loss: 0.0033\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0120 - val_loss: 0.0052\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0092 - val_loss: 0.0034\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0129 - val_loss: 0.0114\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0093 - val_loss: 0.0052\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0112 - val_loss: 0.0051\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0068 - val_loss: 0.0080\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0068 - val_loss: 0.0064\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0096 - val_loss: 0.0071\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0090 - val_loss: 0.0028\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0094 - val_loss: 0.0034\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0065 - val_loss: 0.0039\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0138 - val_loss: 0.0070\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0069 - val_loss: 0.0027\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0108 - val_loss: 0.0045\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0059 - val_loss: 0.0024\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0060 - val_loss: 0.0031\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0085 - val_loss: 0.0026\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0052 - val_loss: 0.0040\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0053 - val_loss: 0.0033\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0140 - val_loss: 0.0024\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0051 - val_loss: 0.0032\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0061 - val_loss: 0.0026\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0055 - val_loss: 0.0026\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0056 - val_loss: 0.0025\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0061 - val_loss: 0.0036\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0064 - val_loss: 0.0025\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0081 - val_loss: 0.0030\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0095 - val_loss: 0.0029\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0061 - val_loss: 0.0017\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0114 - val_loss: 0.0026\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0074 - val_loss: 0.0022\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0084 - val_loss: 0.0037\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0056 - val_loss: 0.0028\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0084 - val_loss: 0.0034\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0134 - val_loss: 0.0027\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0115 - val_loss: 0.0031\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0090 - val_loss: 0.0041\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0150 - val_loss: 0.0033\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0085 - val_loss: 0.0052\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0090 - val_loss: 0.0079\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0068 - val_loss: 0.0024\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0108 - val_loss: 0.0033\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0084 - val_loss: 0.0036\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0060 - val_loss: 0.0044\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0172 - val_loss: 0.0069\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0070 - val_loss: 0.0026\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0061 - val_loss: 0.0037\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0131 - val_loss: 0.0033\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0100 - val_loss: 0.0034\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0118 - val_loss: 0.0033\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0088 - val_loss: 0.0037\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0059 - val_loss: 0.0027\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0088 - val_loss: 0.0022\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0052 - val_loss: 0.0057\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0057 - val_loss: 0.0032\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0085 - val_loss: 0.0044\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0078 - val_loss: 0.0042\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0094 - val_loss: 0.0034\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0053 - val_loss: 0.0037\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0064 - val_loss: 0.0028\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0095 - val_loss: 0.0044\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0087 - val_loss: 0.0035\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0078 - val_loss: 0.0039\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0079 - val_loss: 0.0026\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0080 - val_loss: 0.0038\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0050 - val_loss: 0.0031\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0078 - val_loss: 0.0103\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0057 - val_loss: 0.0033\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0049 - val_loss: 0.0032\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0137 - val_loss: 0.0049\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0077 - val_loss: 0.0031\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0062 - val_loss: 0.0037\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0083 - val_loss: 0.0025\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0052 - val_loss: 0.0042\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0077 - val_loss: 0.0035\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0107 - val_loss: 0.0071\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0078 - val_loss: 0.0035\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0116 - val_loss: 0.0025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8MD_3e4QP4H"
      },
      "source": [
        "xt = train_gen(time_steps, batches, min_index,max_index, ahead, data)"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93GGVfGrZSV_"
      },
      "source": [
        "r,u= next(xt)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDGN567BZXjy",
        "outputId": "2f5c3803-3a23-46f0-8a51-77d6f7456041"
      },
      "source": [
        "r.shape\n",
        "u.shape"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 70, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV9LUJ0BCatu",
        "outputId": "41ac9786-6bbb-4b7a-fe86-a1d2a4a4bfbd"
      },
      "source": [
        "result = model.evaluate(\n",
        "                         xt, \n",
        "                         steps = 140   # Total number of steps (batches of samples) before declaring the evaluation round finished.\n",
        "                        )"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 2s 12ms/step - loss: 0.0030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MClAl5hQasu",
        "outputId": "d140316e-3b9f-48be-f576-e88480c01f6c"
      },
      "source": [
        "result"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0032031990122050047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy6jXWaTadRl"
      },
      "source": [
        "input_dim = X.shape[-1]\n",
        "model_input1 = Input(shape=(time_steps, input_dim))\n",
        "x = LSTM(70, return_sequences=True)(model_input1)\n",
        "x = LSTM(70, return_sequences=False)(x)\n",
        "x = Dense(35)(x)\n",
        "x = Dense(1)(x)\n",
        "model1 = Model(model_input1, x)"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3zptRiadwbK",
        "outputId": "f35a6d8a-acdd-4f2c-d692-a456ecab0e1c"
      },
      "source": [
        "# 4.1 Compile and print model summary\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "print(model1.summary())"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 70, 9)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 70, 70)            22400     \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 70)                39480     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 35)                2485      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 36        \n",
            "=================================================================\n",
            "Total params: 64,401\n",
            "Trainable params: 64,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dStYDjAGd8lY",
        "outputId": "5d1ab0e2-da21-4306-c14d-ca1a1a677e51"
      },
      "source": [
        "H1 = model1.fit(\n",
        "              t,\n",
        "              steps_per_epoch= 60,\n",
        "              validation_data = v,\n",
        "              validation_steps = 10,\n",
        "              epochs= 100)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 9s 98ms/step - loss: 0.0299 - val_loss: 0.0036\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 5s 81ms/step - loss: 0.0041 - val_loss: 0.0035\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0036 - val_loss: 0.0028\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0027 - val_loss: 0.0021\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0024 - val_loss: 0.0021\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0020 - val_loss: 0.0026\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0022\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0013 - val_loss: 8.8013e-04\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0011 - val_loss: 8.6155e-04\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 5s 82ms/step - loss: 0.0010 - val_loss: 9.5152e-04\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 9.7930e-04 - val_loss: 0.0011\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0010 - val_loss: 8.7542e-04\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 5s 83ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 5s 84ms/step - loss: 0.0010 - val_loss: 8.9813e-04\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 9.4844e-04 - val_loss: 9.8135e-04\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0012 - val_loss: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUM7mQ9LeJNN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}