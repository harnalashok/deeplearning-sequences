{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GMnrZQ4Gbrkj",
        "mREgkBqGCjIU",
        "fuA9yPHcDt9C"
      ],
      "mount_file_id": "1nYQ_yt6aHGC51g9vhXgmBkQM5U2jMvbo",
      "authorship_tag": "ABX9TyM3QF/hz0fMaQRzuYvhUQfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning-sequences/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bpOhSsWepIW"
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/text/text_classification_rnn\r\n",
        "# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data.ipynb#scrollTo=m5bz7R1xhX1f\r\n",
        "# https://stackoverflow.com/a/49579995/3282777\r\n",
        "# https://www.tensorflow.org/tutorials/load_data/text\r\n",
        "\r\n",
        "\r\n",
        "# 1.0 Call libraries\r\n",
        "import numpy as np\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLwFoyRnp_y"
      },
      "source": [
        "# 1.1 More libraries\r\n",
        "from tensorflow.keras import utils\r\n",
        "from tensorflow.keras import preprocessing\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94joe0f8bOgM"
      },
      "source": [
        "# 1.2 Set numpy decimal printoptions\r\n",
        "#      Limit display to precision of 3\r\n",
        "\r\n",
        "np.set_printoptions(precision=3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1r3mI9IdjXp"
      },
      "source": [
        "# 1.3\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMnrZQ4Gbrkj"
      },
      "source": [
        "## Introduction to tensors\r\n",
        "Refer this [page](https://www.tensorflow.org/guide/tensor)\r\n",
        "\r\n",
        "Tensors are (kind of) like np.arrays. All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.   \r\n",
        "Rank in tensor is akin to dimensions in numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uexi-Karb7fY"
      },
      "source": [
        "#### Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzu-1fePb2gS",
        "outputId": "ebd5ca26-90bc-4160-9c7d-dddba832388a"
      },
      "source": [
        "# 2.0 Rank 0\r\n",
        "#     A \"scalar\" or \"rank-0\" tensor . \r\n",
        "#       A scalar contains a single value,\r\n",
        "#        and no \"axes\".\r\n",
        "\r\n",
        "print( tf.constant(4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6kfPKlIcUuP",
        "outputId": "33ef601e-1d1a-4ac8-b80c-1ea54a35373f"
      },
      "source": [
        "# 2.1 Rank 1\r\n",
        "#     A \"vector\" or \"rank-1\" tensor is like\r\n",
        "#      a list of values. A vector has one axis:\r\n",
        "\r\n",
        "print(tf.constant([2.0, 3.0, 4.0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga4hLmXvcn4V"
      },
      "source": [
        "# 2.2 Rank 2\r\n",
        "#     A \"matrix\" or \"rank-2\" tensor has two axes:\r\n",
        "\r\n",
        "s=tf.constant(\r\n",
        "              [\r\n",
        "               [1, 2],\r\n",
        "               [3, 4],\r\n",
        "               [5, 6]\r\n",
        "              ]\r\n",
        "             )\r\n",
        "\r\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P50urqBNg4_l"
      },
      "source": [
        "# 2.3 Rank 3\r\n",
        "#     There can be an arbitrary number of\r\n",
        "#      axes (sometimes called \"dimensions\")\r\n",
        "\r\n",
        "rank_3_tensor = tf.constant(\r\n",
        "                             [\r\n",
        "                              [\r\n",
        "                                [0, 1, 2, 3, 4],\r\n",
        "                                [5, 6, 7, 8, 9]\r\n",
        "                               ],\r\n",
        "                              [\r\n",
        "                                [10, 11, 12, 13, 14],\r\n",
        "                                [15, 16, 17, 18, 19]\r\n",
        "                               ],\r\n",
        "                              [\r\n",
        "                               [20, 21, 22, 23, 24],\r\n",
        "                               [25, 26, 27, 28, 29]\r\n",
        "                               ],\r\n",
        "                             ]\r\n",
        "                            )\r\n",
        "\r\n",
        "rank_3_tensor\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RalgNeNiPOA"
      },
      "source": [
        "#### Tensor to numpy\r\n",
        "\r\n",
        "Convert a tensor to numpy array using `np.array` method or using `tensor.numpy` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBUwui-miOZd"
      },
      "source": [
        "# 3.0 Tensor to numpy\r\n",
        "np.array(s)\r\n",
        "print()\r\n",
        "s.numpy()\r\n",
        "print()\r\n",
        "np.array(rank_3_tensor)\r\n",
        "print()\r\n",
        "rank_3_tensor.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh9yxQLoi_oF"
      },
      "source": [
        "#### Basic maths on tensors\r\n",
        "\r\n",
        "Basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtsBErDxjCYl"
      },
      "source": [
        "# 3.1\r\n",
        "a = tf.constant([[1, 2],\r\n",
        "                 [3, 4]])\r\n",
        "b = tf.constant([[1, 2],\r\n",
        "                 [1, 0]])\r\n",
        "c = tf.ones([2,3])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXRt5VtnjI6u"
      },
      "source": [
        "# 3.2\r\n",
        "a+b\r\n",
        "print()\r\n",
        "tf.add(a,b)\r\n",
        "\r\n",
        "print()\r\n",
        "a * b\r\n",
        "print()\r\n",
        "tf.multiply(a,b)\r\n",
        "\r\n",
        "print()\r\n",
        "tf.matmul(a,b)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE58845ph3ZR"
      },
      "source": [
        "# 3.3 This fails. Tensors are very sensitive \r\n",
        "#     to data types\r\n",
        "\r\n",
        "r = tf.constant([1.0,2.0], shape = [2,1])\r\n",
        "p = tf.constant(5)\r\n",
        "r * p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4_1PKTIwR9-"
      },
      "source": [
        "# 3.4 This also fails\r\n",
        "#      even though both operands\r\n",
        "#       are floats\r\n",
        "\r\n",
        "r = tf.constant([1.0,2.0], shape = [2,1])\r\n",
        "r\r\n",
        "p = tf.constant(5)\r\n",
        "r * tf.cast(p, tf.float16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dUIdw1UwYXc"
      },
      "source": [
        "# 3.5 This succeeds\r\n",
        "\r\n",
        "r = tf.constant([1.0,2.0], shape = [2,1])\r\n",
        "r\r\n",
        "p = tf.constant(5)\r\n",
        "r * tf.cast(p, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIKuOezIkWEZ"
      },
      "source": [
        "Some operations on tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdysmiW9j3tE"
      },
      "source": [
        "# 4.0\r\n",
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\r\n",
        "\r\n",
        "# 4.1 Find the largest value\r\n",
        "print(tf.reduce_max(c))\r\n",
        "\r\n",
        "# 4.2 Find the index of the largest value\r\n",
        "print(tf.argmax(c))\r\n",
        "\r\n",
        "# 4.3 Compute the softmax\r\n",
        "#     Note that each 'row'\r\n",
        "#     (or axis 0) or putput \r\n",
        "#     sums to 1\r\n",
        "print(tf.nn.softmax(c))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTN8TbHYmXN8"
      },
      "source": [
        "#### Some vocabulary\r\n",
        "Tensors have shapes. Some vocabulary:\r\n",
        "\r\n",
        "> **Shape**: The length (number of elements) of each of the axes of a tensor.  \r\n",
        "> **Rank**: Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.  \r\n",
        "> **Axis** or Dimension: A particular dimension of a tensor.  \r\n",
        "> **Size**: The total number of items in the tensor, the product shape vector.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLS_ln0ZmyY9"
      },
      "source": [
        "# 5.0\r\n",
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])\r\n",
        "# axis 0 is 3\r\n",
        "# axis -1 is 5"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTom9iVSmzz8"
      },
      "source": [
        "\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvaOYuTDnSdu"
      },
      "source": [
        "# 5.2 Like in numpy arrays, we have attributes:\r\n",
        "#      dtype, ndim, shape\r\n",
        "\r\n",
        "rank_4_tensor.dtype\r\n",
        "print()\r\n",
        "rank_4_tensor.ndim\r\n",
        "print()\r\n",
        "rank_4_tensor.shape\r\n",
        "print()\r\n",
        "rank_4_tensor.shape[0]\r\n",
        "print()\r\n",
        "rank_4_tensor.shape[-1]\r\n",
        "print()\r\n",
        "tf.size(rank_4_tensor).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPfW3kVvnsal"
      },
      "source": [
        "It is important to keep in mind inherent or implied meaning of each axis. In the above example, here are the implied meanings: \r\n",
        "\r\n",
        "*Batch size:* 3  \r\n",
        "*Depth*:      2  \r\n",
        "*Width*:      4  \r\n",
        "*Height*:     5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ydZqDQMoXxp"
      },
      "source": [
        "### Indexing (See [here](https://www.tensorflow.org/guide/tensor#indexing))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uFFa2eWOrPB"
      },
      "source": [
        "Single-axis indexing\r\n",
        "\r\n",
        "TensorFlow follows standard Python indexing rules, similar to indexing a list or a string in Python, and the basic rules for NumPy indexing.\r\n",
        "\r\n",
        "> indexes start at 0  \r\n",
        "> negative indices count backwards from the end  \r\n",
        "> colons, :, are used for slices: start:stop:step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w751n7s8O6wh",
        "outputId": "8cce7a5e-1159-4d98-e381-34091418785e"
      },
      "source": [
        "# 6.0 Sample 1-axes tensor\r\n",
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\r\n",
        "print(rank_1_tensor.numpy())\r\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFUlY418PJY_"
      },
      "source": [
        "# 6.2 Indexing with a : slice keeps the axis:\r\n",
        "\r\n",
        "#6.2.1 Everything\r\n",
        "rank_1_tensor[:].numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "#6.2.2 Before 4:\r\n",
        "rank_1_tensor[:4].numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "#6.2.3 From 4 to the end\r\n",
        "rank_1_tensor[4:].numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "#6.2.4 From 2, before 7:\r\n",
        "rank_1_tensor[2:7].numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "#6.2.5 Every other item\r\n",
        "rank_1_tensor[::2].numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "#6.2.6 Reversed\r\n",
        "rank_1_tensor[::-1].numpy()\r\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT9HvhXLQCp4"
      },
      "source": [
        "### Manipulating shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I-aGPVSQFWQ"
      },
      "source": [
        "# 7.0 Shape returns a `TensorShape` object\r\n",
        "#     that shows the size along each axis\r\n",
        "\r\n",
        "x = tf.constant([[1], [2], [3]])\r\n",
        "print(x.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvmfeaqEQQdS"
      },
      "source": [
        "You can reshape a tensor into a new shape. The tf.reshape operation is fast and cheap as the underlying data does not need to be duplicated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkNLGU51QRlo"
      },
      "source": [
        "# 7.1 You can reshape a tensor to a new shape.\r\n",
        "#     Note that you're passing in a list\r\n",
        "\r\n",
        "reshaped = tf.reshape(x, [1, 3])\r\n",
        "reshaped.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcGI1zmiR2vj"
      },
      "source": [
        "# 7.2 We created this tensor earlier\r\n",
        "\r\n",
        "print(rank_3_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwIYHmucSEVB"
      },
      "source": [
        "If you flatten a tensor you can see what order it is laid out in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8jysZW-SAI6"
      },
      "source": [
        "#7.3  A `-1` passed in the `shape` argument\r\n",
        "#     says \"Whatever fits\".\r\n",
        "\r\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hl_dugQSSOx"
      },
      "source": [
        "Typically the only reasonable use of tf.reshape is to combine or split adjacent axes (or add/remove 1s).\r\n",
        "\r\n",
        "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svSYmuTXSVzS"
      },
      "source": [
        "# 7.4\r\n",
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\r\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-elksX2JSqc5"
      },
      "source": [
        "#### Reshaping can be a mess\r\n",
        "\r\n",
        "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes. It will be a mess."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsblUXOnSpFs"
      },
      "source": [
        "# 8.0 Bad examples: don't do this\r\n",
        "#     Only multiply adjacent indices\r\n",
        "\r\n",
        "# 8.1 You can't reorder axes with reshape.\r\n",
        "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \r\n",
        "\r\n",
        "# 8.2 This is a mess\r\n",
        "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOKbmHcKUkoM"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlcrMMZYUxh0"
      },
      "source": [
        "Broadcasting is a concept borrowed from the equivalent feature in NumPy. In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\r\n",
        "\r\n",
        "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkHYzDGIXPAe"
      },
      "source": [
        "# 9.0\r\n",
        "x = tf.constant([1, 2, 3])\r\n",
        "y = tf.constant(2)\r\n",
        "z = tf.constant([2, 2, 2])"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgdWHQIuXQwX"
      },
      "source": [
        "# 9.1\r\n",
        "x * y\r\n",
        "x + z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voF3bhqYXx_U"
      },
      "source": [
        "Likewise, axes with length 1 can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.\r\n",
        "\r\n",
        "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is [4]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoBRTXpKX07z"
      },
      "source": [
        "# 9.2 These are the same computations\r\n",
        "x = tf.reshape(x,[3,1])\r\n",
        "y = tf.range(1, 5)\r\n",
        "\r\n",
        "# 9.2.1\r\n",
        "print(x, \"\\n\")\r\n",
        "print(y, \"\\n\")\r\n",
        "print(tf.multiply(x, y))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HyodlpPWITS"
      },
      "source": [
        "# 9.2.2\r\n",
        "x = tf.constant([1, 2, 3])\r\n",
        "y = tf.constant(2)\r\n",
        "z = tf.constant([2, 2, 2])\r\n",
        "\r\n",
        "# 9.2.3 All of these are the same computation\r\n",
        "print(tf.multiply(x, 2))\r\n",
        "print(x * y)\r\n",
        "print(x * z)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U6saW9wPgrJ"
      },
      "source": [
        "#### Logical operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO2PEKoJ9-Qx"
      },
      "source": [
        "# 9.3 Logical operations on tensors\r\n",
        "#     Pl refer: tf.math\r\n",
        "#           https://www.tensorflow.org/api_docs/python/tf/math\r\n",
        "\r\n",
        "print(tf.constant([1,2,10]) < 5)\r\n",
        "print(tf.constant([True, False, True,True], dtype = tf.bool))\r\n",
        "\r\n",
        "# 9.4 A tensor can be reshaped as per its shape argument\r\n",
        "\r\n",
        "print(tf.constant(np.arange(20), shape = [5,4])) \r\n",
        "x = tf.constant(np.arange(20), shape = [5,4])\r\n",
        "# Display Ist two rows and columns\r\n",
        "x[: 2, :2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNJOZ6iJEZ0g"
      },
      "source": [
        "# 9.5 Show first and third rows\r\n",
        "#     This works as an exception\r\n",
        "\r\n",
        "x[tf.constant([True, False,True,False, False], dtype = tf.bool)]\r\n",
        "\r\n",
        "# But the following do not work:\r\n",
        "# Valid indices are: integers, slices (`:`),\r\n",
        "#    ellipsis (`...`), tf.newaxis (`None`)\r\n",
        "#      and scalar tf.int32/tf.int64 tensors \r\n",
        "\r\n",
        "#x[\r\n",
        "#   tf.constant([True, False,True,False, False], dtype = tf.bool),\r\n",
        "#   tf.constant([True, False,True,False], dtype = tf.bool)\r\n",
        "#  ]\r\n",
        "\r\n",
        "#x[\r\n",
        "#   tf.constant([1,0,0,1,0], dtype = tf.int32),\r\n",
        "#   tf.constant([1,0,1,0], dtype = tf.int32)\r\n",
        "#  ]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZsmojwk9xN1"
      },
      "source": [
        "### Custom loss function\r\n",
        "Refer: Page 384 of Book by Aurelion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp-krA5lzkDf",
        "outputId": "c094ee84-4caa-4830-87f2-e805d73a6ebd"
      },
      "source": [
        "# 10.0 Define a model\r\n",
        "import pandas as pd\r\n",
        "from tensorflow import keras\r\n",
        "from sklearn.datasets import load_boston\r\n",
        "# 10.1\r\n",
        "X,y = load_boston(return_X_y= True)\r\n",
        "X.shape   # (506, 13)\r\n",
        "# 10.2\r\n",
        "model = keras.models.Sequential(\r\n",
        "                                 [\r\n",
        "                                  keras.layers.Dense(5, activation = 'relu'),\r\n",
        "                                  keras.layers.Dense(1,activation = 'sigmoid')\r\n",
        "                                 ]\r\n",
        "                               )\r\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DrvGgT3SXeh"
      },
      "source": [
        "#### Huber loss\r\n",
        "\r\n",
        "For a comparative picture of loss functions being used in Regression, see [here](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0). Briefly, if data is noisy, use MAE and if their are more outliers or noise, use huber loss.  \r\n",
        "\r\n",
        "Huber loss is less sensitive to outliers in data than the squared error loss. It’s also differentiable at 0 (unlike MAE). It’s basically absolute error, which becomes quadratic when error is small. How small that error has to be to make it quadratic depends on a hyperparameter, 𝛿 (delta), which can be tuned.   \r\n",
        "\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKx9n8Py1B_8"
      },
      "source": [
        "# 10.3 Custom loss function\r\n",
        "def huber_loss(y_true,y_pred):\r\n",
        "  error = y_true - y_pred\r\n",
        "  is_small_error = tf.abs(error) < 1.0\r\n",
        "  squared_loss = tf.square(error) / 2.0\r\n",
        "  linear_loss = tf.abs(error) - 0.5\r\n",
        "  return tf.where(is_small_error, squared_loss, linear_loss)\r\n",
        "\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euV-XwYhRnFq"
      },
      "source": [
        "# 10.4 Compile and run the model with our loss function\r\n",
        "model.compile(loss= huber_loss, metrics = \"mse\", optimizer = \"nadam\")\r\n",
        "model.fit(X,y,epochs = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjuKqtxoCQNF"
      },
      "source": [
        "#### Generate random tensors\r\n",
        "Refer this [article](https://www.tensorflow.org/guide/random_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoeshkM9CPfl"
      },
      "source": [
        "# 11.0 Generate random data using\r\n",
        "#      Generator object\r\n",
        "g1 = tf.random.Generator.from_seed(1)\r\n",
        "\r\n",
        "# 2.0.1 Use object 'g1'\r\n",
        "g1.normal([2,3])\r\n",
        "print()\r\n",
        "# 2.0.2\r\n",
        "g1.uniform([1])\r\n",
        "print()\r\n",
        "\r\n",
        "# 11.1 Generate random data\r\n",
        "#      directly\r\n",
        "tf.random.uniform([4])    # shape is (4,)\r\n",
        "print()\r\n",
        "tf.random.uniform([4]).shape\r\n",
        "print()\r\n",
        "tf.random.uniform([4]).numpy()\r\n",
        "print()\r\n",
        "\r\n",
        "# 11.2\r\n",
        "tf.random.normal(shape = (10,4), mean = 3,stddev=1.3)\r\n",
        "print()\r\n",
        "tf.random.normal(shape = (10,4), mean = 3,stddev=1.3).shape\r\n",
        "print()\r\n",
        "\r\n",
        "# 2.2\r\n",
        "tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ_t9j9cgIir"
      },
      "source": [
        "## tf.data.Dataset API\r\n",
        "Understanding Dataset object. The `tf.data.Dataset` API supports writing descriptive and efficient **input pipelines**. Dataset usage follows a common pattern (see [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) and [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data.ipynb#scrollTo=k_5N7CdNGYAa) ):\r\n",
        "\r\n",
        ">  Create a source dataset from your input data.\r\n",
        "\r\n",
        ">  Write dataset transformations to preprocess the data.\r\n",
        "\r\n",
        ">  Iterate over the dataset and process the elements.\r\n",
        "\r\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory. That is processing is performed batch-wise.  \r\n",
        "\r\n",
        "The simplest way to create a dataset is to create it from a python list:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mREgkBqGCjIU"
      },
      "source": [
        "#### from_tensors() vs from_tensor_slices()\r\n",
        "See this [stackoverflow answer](https://stackoverflow.com/a/49579995/3282777)  \r\n",
        "\r\n",
        "Read `from_tensor_slices()` as `to_tensor_slices()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0cZ_HnU3CsP"
      },
      "source": [
        "# 1.0 Call libraries\r\n",
        "import numpy as np\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_FF7_Kr6GT0"
      },
      "source": [
        "# 1.1 More libraries\r\n",
        "from tensorflow.keras import utils\r\n",
        "from tensorflow.keras import preprocessing\r\n",
        "import pathlib\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUKki2X43SLk"
      },
      "source": [
        "# 1.2 Set numpy decimal printoptions\r\n",
        "#      Limit display to precision of 3\r\n",
        "\r\n",
        "np.set_printoptions(precision=3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC7fM6SD3pPE"
      },
      "source": [
        "# 1.3\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_5IV3W2Zb4c"
      },
      "source": [
        "# 2.0 Read from_tensor_slices as to_tensor_slices()\r\n",
        "# 2.0.1 from_tensor_slices()\r\n",
        "dataset1 = tf.data.Dataset.from_tensor_slices([[1,2],[3,4],[5,6]])\r\n",
        "# 2.0.2 from_tensors\r\n",
        "dataset2 = tf.data.Dataset.from_tensors([[1,2],[3,4],[5,6]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h581hc2ZcVd",
        "outputId": "b81922fd-ae8b-4b7f-8da7-3795188068b0"
      },
      "source": [
        "# 2.1 Print the two objects\r\n",
        "dataset1\r\n",
        "print()\r\n",
        "dataset2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (2,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorDataset shapes: (3, 2), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE8AHBsSZcs3",
        "outputId": "53aacc16-ff75-4254-e72c-084ba2a5b888"
      },
      "source": [
        "# 2.2 Extract each element from\r\n",
        "#      dataset. dataset is iterable.\r\n",
        "#       Four elements. Each has two values\r\n",
        "\r\n",
        "for elem in dataset1:\r\n",
        "  print(\"--\")\r\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--\n",
            "[1 2]\n",
            "--\n",
            "[3 4]\n",
            "--\n",
            "[5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCqpiOFHd9TJ",
        "outputId": "296538ee-67d9-4f9f-f5d2-5e7ce84eb926"
      },
      "source": [
        "# 2.2.1 Just one element\r\n",
        "\r\n",
        "for elem in dataset2:\r\n",
        "  print(\"--\")\r\n",
        "  print(elem)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]], shape=(3, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF9EGxD0en9g"
      },
      "source": [
        "# 2.3\r\n",
        "dataset3 = tf.data.Dataset.from_tensor_slices(\r\n",
        "                                              (\r\n",
        "                                               tf.random.uniform([4]), # shape [4]\r\n",
        "                                               tf.random.normal(\r\n",
        "                                                                [4, 6],\r\n",
        "                                                                mean=1.5,\r\n",
        "                                                                stddev=2.2\r\n",
        "                                                                ) \r\n",
        "                                               )\r\n",
        "                                              )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER1HNw5-jY3V",
        "outputId": "96b135b3-1e60-42de-87b1-505f476c2912"
      },
      "source": [
        "# 2.3.1 Print contents\r\n",
        "for elem in dataset3:\r\n",
        "  # Four elements.\r\n",
        "  # Each element is a tuple of two tensors\r\n",
        "  # one from uniform and the other from normal dist\r\n",
        "  print(elem)   \r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=float32, numpy=0.2308768>, <tf.Tensor: shape=(6,), dtype=float32, numpy=array([-1.476,  7.276,  0.228,  3.193,  2.923,  0.521], dtype=float32)>)\n",
            "(<tf.Tensor: shape=(), dtype=float32, numpy=0.8270308>, <tf.Tensor: shape=(6,), dtype=float32, numpy=array([ 2.976, -1.021,  1.489, -1.378,  5.806, -1.429], dtype=float32)>)\n",
            "(<tf.Tensor: shape=(), dtype=float32, numpy=0.14125514>, <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.491, 4.323, 2.083, 3.948, 2.935, 2.654], dtype=float32)>)\n",
            "(<tf.Tensor: shape=(), dtype=float32, numpy=0.57362044>, <tf.Tensor: shape=(6,), dtype=float32, numpy=array([ 1.875,  1.325,  1.823, -1.774,  5.792,  3.923], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3m5aXGBZSJ"
      },
      "source": [
        "# 2.4 Next same internal contents but using from_tensors\r\n",
        "dataset4 = tf.data.Dataset.from_tensors(\r\n",
        "                                         (\r\n",
        "                                           tf.random.uniform([4]),    # shape [4]\r\n",
        "                                           tf.random.normal([4, 6], mean=1.5,stddev=2.2) # [4,100]\r\n",
        "                                          )\r\n",
        "                                        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JTgvrihBa5D",
        "outputId": "2aedea17-cdea-4a54-fa1b-7337bcf08f8a"
      },
      "source": [
        "# 2.4.1\r\n",
        "for elem in dataset4:\r\n",
        "  # One element\r\n",
        "  # This elem is a tuple of two tensors\r\n",
        "  print()\r\n",
        "  print(elem)   "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.52 , 0.01 , 0.11 , 0.324], dtype=float32)>, <tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
            "array([[ 2.189,  1.342,  2.591, -0.121,  0.247,  2.917],\n",
            "       [ 2.694,  2.623,  1.488,  5.46 , -0.065,  1.36 ],\n",
            "       [ 0.13 ,  2.027, -3.341,  3.226,  4.435,  2.126],\n",
            "       [ 0.062, -0.098,  0.346, -0.038,  2.953,  2.251]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2kKHMHxrvKD"
      },
      "source": [
        "#help(tfds.load)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuA9yPHcDt9C"
      },
      "source": [
        "### Dataset object from numpy-arrays in memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEcNNEtLEXch"
      },
      "source": [
        "If all data is in memory, to create a `Dataset` object, use  `Dataset.from_tensor_slices()` on numpy arrays (in memory)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k45JNeUHbVZ0",
        "outputId": "f8014200-74fc-479b-84df-6634fc671f07"
      },
      "source": [
        "# 3.0 Download numpy arrays to \r\n",
        "#     two objects (train,test) in memory\r\n",
        "\r\n",
        "# 3.0.1 First delete any existing folder\r\n",
        "\r\n",
        "!rm -rf /root/.keras/datasets\r\n",
        "!ls -la /root/.keras"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Mar 11 05:52 .\n",
            "drwx------ 1 root root 4096 Mar 11 05:52 ..\n",
            "-rw-r--r-- 1 root root  123 Mar 11 05:52 keras.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmaE6PjjhQ47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad503b1a-cc3c-4469-d852-a04d627f651b"
      },
      "source": [
        "# 3.0.2 Next download data:\r\n",
        "train, test = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G--8m0n6bRbb",
        "outputId": "a38fa957-2eaa-412b-8794-d962b84431ed"
      },
      "source": [
        "# 3.0.3 Check downloaded files\r\n",
        "! ls -la /root/.keras/datasets"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Mar 11 06:07 .\n",
            "drwxr-xr-x 3 root root 4096 Mar 11 06:07 ..\n",
            "drwxr-xr-x 2 root root 4096 Mar 11 06:07 fashion-mnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz6m-_23Et-z",
        "outputId": "973d90d0-5ec3-4ee8-fa48-8d3800ab7716"
      },
      "source": [
        "# 4.1 Little more checking:\r\n",
        "\r\n",
        "type(train)\r\n",
        "print()\r\n",
        "type(train[0])\r\n",
        "print()\r\n",
        "type(test[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCQV0Tj-E7hp"
      },
      "source": [
        "# 4.2 Separate images and labels:\r\n",
        "images,labels = train\r\n",
        "\r\n",
        "# 4.2.1 Do something with images\r\n",
        "images = images/255"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbbNabbTFHja",
        "outputId": "a31a60b0-b6e7-4c96-f6b1-46eee6cdd5f3"
      },
      "source": [
        "# 4.3 Create Dataset object. \r\n",
        "#      It is similar to way we did in #3.3 above:\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\r\n",
        "type(dataset)\r\n",
        "dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxtlBF0rRREK"
      },
      "source": [
        "### Dataset object from textfiles on disk\r\n",
        "Please see this [tutorial](https://www.tensorflow.org/tutorials/load_data/text). We are downloading files from stackoverflow. The file contains questions asked on some subjects. (This section is to be completed.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFoLaaTzJEka"
      },
      "source": [
        "#### Consuming text files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjbiMHZEqv3f"
      },
      "source": [
        "##### Download file from a url\r\n",
        "How to download a file from a URL.\r\n",
        "This way any file can also be downloaded from *gdrive* without mounting it. Uses [`get_file()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) utility of `tf.keras.utils`. See this [example](https://www.tensorflow.org/tutorials/load_data/text)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V--qG7rdfYkZ"
      },
      "source": [
        "# 5.0 Which files are where:\r\n",
        "\r\n",
        "!ls -la /root/.keras/\r\n",
        "!ls -la /root/.keras/datasets\r\n",
        "\r\n",
        "# 5.0.1 Deleting datasets dir\r\n",
        "!rm -rf /root/.keras/datasets\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afTuj2_1nyg9",
        "outputId": "bec9471b-ae92-45b2-dc58-e32467314de1"
      },
      "source": [
        "# 5.1 Specify file URL from stackoverflow.\r\n",
        "#     Our file: stack_overflow_16k.tar.gz\r\n",
        "\r\n",
        "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\r\n",
        "\r\n",
        "# 5.1.1 Use keras get_file() utility\r\n",
        "dnld = utils.get_file(\r\n",
        "                           'stack_overflow_16k.tar.gz',  \r\n",
        "                            data_url,\r\n",
        "                            untar=True,\r\n",
        "                          )\r\n",
        "\r\n",
        "# 5.1.2 Where is 'dnld' object?\r\n",
        "#       Get its path\r\n",
        "dnld_dir = pathlib.Path(dnld).parent\r\n",
        "dnld_dir     # '/root/.keras/datasets'"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\n",
            "6053888/6053168 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLJ5_B049gBl"
      },
      "source": [
        "# 5.1.3\r\n",
        "! ls -la /root/.keras/datasets\r\n",
        "\r\n",
        "# 5.1.4 Result after untarring\r\n",
        "! ls -la /root/.keras/datasets/train\r\n",
        "! ls -la /root/.keras/datasets/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afE_vbH-JNFZ"
      },
      "source": [
        "##### Download file from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yBg7Gsl8rY-",
        "outputId": "6d1aa110-1d49-484f-ae1d-54e239e21e3b"
      },
      "source": [
        "# 5.2 gdrive download: May also download a shared file from gdrive\r\n",
        "#     No need to mount gdrive\r\n",
        "#     Download 'archive.csv.zip' from my gdrive:\r\n",
        "\r\n",
        "gdrive_url = \"https://drive.google.com/file/d/14gjcWMRJORJ4bQ2QerWaodDpLi5oDcxM/view?usp=sharing\"\r\n",
        "\r\n",
        "# 5.2.1 Use keras get_file() utility\r\n",
        "dnld_gdrive = utils.get_file(\r\n",
        "                           'archive.csv.zip',  \r\n",
        "                            gdrive_url,\r\n",
        "                          )\r\n",
        "\r\n",
        "# 5.2.2 Where is 'dataset' object?\r\n",
        "#       Get its path\r\n",
        "gdrive_dir = pathlib.Path(dnld_gdrive).parent\r\n",
        "gdrive_dir   # PosixPath('/root/.keras/datasets')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://drive.google.com/file/d/14gjcWMRJORJ4bQ2QerWaodDpLi5oDcxM/view?usp=sharing\n",
            "   8192/Unknown - 0s 0us/step"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTVTY54uXS_N"
      },
      "source": [
        "# 5.2.3 Check folders under 'train'\r\n",
        "! ls -la /root/.keras/datasets/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR8vk3flLjDx"
      },
      "source": [
        "##### Create a dataset of text-lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4a9BiqtgggV"
      },
      "source": [
        "# 6.0 Files in 'train/python' folder\r\n",
        "train_dir = \"/root/.keras/datasets/train/\"\r\n",
        "python_files = os.listdir(train_dir + \"python\")\r\n",
        "python_files[:3]\r\n",
        "print()\r\n",
        "\r\n",
        "# 6.0.1 Join directory path to file-names\r\n",
        "files_with_path = [os.path.join(train_dir, file) for file in python_files]\r\n",
        "files_with_path[:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbd009xAhZ7"
      },
      "source": [
        "# 6.1 tf.data.Dataset of just filepaths\r\n",
        "#     Prepare a dataset of all files matching\r\n",
        "#     one or more glob patterns.\r\n",
        "\r\n",
        "filepath_dataset_py = tf.data.Dataset.list_files(\"/root/.keras/datasets/train/python/*.txt\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--WfgNMLGuXK"
      },
      "source": [
        "# 6.2 Create a datset comprising lines from one or more text files.\r\n",
        "\r\n",
        "data_lines = tf.data.TextLineDataset(filepath_dataset_py)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hE3fBwOHETo",
        "outputId": "29a7d7d9-bba0-4a15-d4be-b40acda30484"
      },
      "source": [
        "# 6.2.1 Examine 5 files:\r\n",
        "\r\n",
        "for line in data_lines.take(5):\r\n",
        "  print(line.numpy)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\"blank submodule imports using __init__.py i\\'m learning blank, and i can\\'t figure out how imports in __init__.py work...i understand from the blank tutorial that the __init__.py file initializes a package, and that i can import subpackages here...i\\'m doing something wrong, though. could you explain for me (and for future blank-learners) what i\\'m doing wrong?..here\\'s a simplified example of what i\\'m trying to do...this is my file structure:..package.    __init__.py.    test.py.    subpackage.        __init__.py.        hello_world.py...the contents of hello_world.py:..def do_something():.    print \"\"hello, world!\"\"...subpackage/__init__.py is empty...package/__init__.py contains:..import test.submodule.do_something...and finally, test.py contains:..do_something()...this is how i attempt to run hello_world.py using osx terminal and blank 3:..blank test.py...blank then throws the following error:..nameerror: name \\'do_something\\' is not defined\"'>>\n",
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\"blank - is there a way to get all the attributes of an object so i have a class called \\'car\\' in another .py file (myclasses.py)..class car:.    tires = 4.    color = \"\"\"\".    speed = 0.    engine = \"\"\"\"...and in my main..import myclasses..ferrari = myclasses.car().ferrari.color = \"\"red\"\".ferrari.engine = \"\"fast\"\".ferrari.speed = 200..for prpty in ferrari:.    print(prpty)...the output i want is like this:..tires = 4.color = red.speed = 200.engine = fast...i know the format of the output depends on me. only if in my for-loop i can get the property name and its value base on my object.\"'>>\n",
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\"sequence switch in blank i am solving a problem in blank. ..the general idea is that given a sequence of numbers, then pick out the numbers form this sequence according to a rule, then this pick-out numbers form a new list...step1, pick out the numbers in odd position (the position count from zero) and append to a new list. ..step2, the remaining numbers form a new sequence...step3, in the next round, pick out the numbers in even position of the new sequence, and append to a new list...step4,  after this round, the remaining numbers forms a a new sequences. ..repeat this procedure until all the number in the original sequence have been pick out to for a new list. ..for example, given a sequence [0, 1, 2, 3, 4, 5, 6, 7, 8], ..step1, pick out the numbers in odd position, new_list = [1, 3, 5, 7] ..step2, the remaining numbers form a new sequence is [0, 2, 4, 6, 8]..step3, pick out the numbers in even position of the new sequence, then the numbers [0, 4, 8] are picked out from the new sequence, and append to new list. then  new_list = [1, 3, 5, 7, 0, 4, 8] ..step4, the remaining numbers form a new sequence is [2, 6]..repeat step 1, then 6 is picked out append to  new_list = [1, 3, 5, 7, 0, 4, 8, 6] .repeat step 2, then 2 is picked out append to new_list = [1, 3, 5, 7, 0, 4, 8, 6, 2], then all numbers in original list are picked out. and the final result is the new_list...i do not know how to implement it in blank. i got stuck in the first step, i want to use a for loop over the sequence and pick out the numbers according to odd or even index. but after picking out the numbers, the sequence changes. then i have to start over a new for loop to loop over this new sequence, if the original sequence is very long. i will be too long and inefficient coding. could someone gives me idea how to deal with this problem?\"'>>\n",
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\"input variables in one line i have a problem with reading variables in one line.  i used a map(int, input().splite()) when i know the number of variables, but in this case in every run of code this number is different. (blank 3)\"'>>\n",
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\"print line in specific order i want to print around 10 lines in such a way that in every sequence 9 lines print with sign \\'-\\'. for example, if x=[1,2,3,4,5]. now i want to print in following sequence,.. 1.-2.-3.-4.-5..-1.2.-3.-4.-5..-1.-2.3.-4.-5...etc. ...please help me to solve this.\"'>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYWTMxwLzJL"
      },
      "source": [
        "### Consuming csv data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WigYyzDTMEti"
      },
      "source": [
        "See [Loading CSV Files](../tutorials/load_data/csv.ipynb), and [Loading Pandas DataFrames](../tutorials/load_data/pandas.ipynb) for more examples. The CSV file format is a popular format for storing tabular data in plain text. For example:  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQt85P3_X3kF"
      },
      "source": [
        "# 7.0 Download titanic file 'train.csv'\r\n",
        "#     from a URL:\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "titanic_file = tf.keras.utils.get_file(\r\n",
        "                                       \"train.csv\",\r\n",
        "                                       \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\r\n",
        "                                       )"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mBzbTfV-X82N",
        "outputId": "5f30eb7b-d1c9-4edf-a72d-6f45c6bdc4ba"
      },
      "source": [
        "# 7.1 Read downloaded file:\r\n",
        "\r\n",
        "df = pd.read_csv(titanic_file)\r\n",
        "df.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyV6yijCYXnd"
      },
      "source": [
        "If your data fits in memory the same Dataset.from_tensor_slices method works on dictionaries, allowing this data to be easily imported:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49D7zXY3X8ZN"
      },
      "source": [
        "# 7.2 Transform pandas dataframe to dictionary\r\n",
        "dict(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBm86pZdZYim"
      },
      "source": [
        "# 8.0 Create tf.data.Dataset objects:\r\n",
        "#     tensor_slice: Slices along along first dimension. \r\n",
        "#     This operation preserves the structure of the input\r\n",
        "#     tensors, removing the first dimension of each tensor\r\n",
        "#     and using it as the dataset dimension. \r\n",
        "\r\n",
        "titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\r\n",
        "type(titanic_slices)   # TensorSliceDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8cl04hqZgvN",
        "outputId": "bc81b489-237c-4c7d-d026-22557edc1344"
      },
      "source": [
        "# 8.1 Just extract one row/batch\r\n",
        "n = 1\r\n",
        "for feature_batch in titanic_slices.take(n):\r\n",
        "  for key, value in feature_batch.items():\r\n",
        "    print(\"  {}:{}\".format(key, value))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  survived:0\n",
            "  sex:b'male'\n",
            "  age:22.0\n",
            "  n_siblings_spouses:1\n",
            "  parch:0\n",
            "  fare:7.25\n",
            "  class:b'Third'\n",
            "  deck:b'unknown'\n",
            "  embark_town:b'Southampton'\n",
            "  alone:b'n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwsBc1WgioQo"
      },
      "source": [
        "A more scalable approach is to load from disk as necessary. The tf.data module provides methods to extract records from one or more CSV files fron disk.\r\n",
        "\r\n",
        "The `experimental.make_csv_dataset` function is the high level interface for reading sets of csv files. It supports column type inference and many other features, like batching and shuffling, to make usage simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKW_qoblbZCn"
      },
      "source": [
        "# 8.2\r\n",
        "batch_size = 4\r\n",
        "titanic_batches = tf.data.experimental.make_csv_dataset(\r\n",
        "                                                         titanic_file,\r\n",
        "                                                         batch_size=batch_size,\r\n",
        "                                                         label_name=\"survived\"\r\n",
        "                                                         )"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe63JICXboUG",
        "outputId": "6bf47d6c-9679-45ff-8547-591892d46a45"
      },
      "source": [
        "# 8.3 Get just one batch\r\n",
        "#     Batch size is 4\r\n",
        "\r\n",
        "howManyBatches = 1\r\n",
        "for feature_batch, label_batch in titanic_batches.take(howManyBatches):\r\n",
        "  print(\"'survived': {}\".format(label_batch))\r\n",
        "  print(\"features:\")\r\n",
        "  for key, value in feature_batch.items():\r\n",
        "    print(\"  {!r:20s}: {}\".format(key, value))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'survived': [1 0 1 0]\n",
            "features:\n",
            "  'sex'               : [b'male' b'male' b'female' b'female']\n",
            "  'age'               : [ 9. 28. 40.  2.]\n",
            "  'n_siblings_spouses': [1 0 1 0]\n",
            "  'parch'             : [1 0 1 1]\n",
            "  'fare'              : [ 15.9     7.896 134.5    10.462]\n",
            "  'class'             : [b'Third' b'Third' b'First' b'Third']\n",
            "  'deck'              : [b'unknown' b'unknown' b'E' b'G']\n",
            "  'embark_town'       : [b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\n",
            "  'alone'             : [b'n' b'y' b'n' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0KGs168eUx7"
      },
      "source": [
        "You can use the select_columns argument if you only need a subset of columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0WPXCDseXmf"
      },
      "source": [
        "# 8.4\r\n",
        "titanic_batches = tf.data.experimental.make_csv_dataset(\r\n",
        "    titanic_file, batch_size=4,\r\n",
        "    label_name=\"survived\", select_columns=['class', 'fare', 'survived'])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9w8qKlWeb6o",
        "outputId": "99571552-04b1-435c-fc63-2334e869f9dd"
      },
      "source": [
        "# 8.5\r\n",
        "for feature_batch, label_batch in titanic_batches.take(1):\r\n",
        "  print(\"'survived': {}\".format(label_batch))\r\n",
        "  for key, value in feature_batch.items():\r\n",
        "    print(\"  {!r:20s}: {}\".format(key, value))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'survived': [1 1 0 0]\n",
            "  'fare'              : [ 26.    135.633  27.     25.467]\n",
            "  'class'             : [b'Second' b'First' b'Second' b'Third']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvncZDgzlyH"
      },
      "source": [
        "#### Preprocessing.text_dataset_from_directory\r\n",
        "The `preprocessing.text_dataset_from_directory()` expects a directory structure as follows. Read more about it [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/*text_dataset_from_directory*).\r\n",
        "\r\n",
        "main_directory/<br>\r\n",
        "...class_a/<br>\r\n",
        "......a_text_1.txt<br>\r\n",
        "......a_text_2.txt<br>\r\n",
        "...class_b/<br>\r\n",
        "......b_text_1.txt<br>\r\n",
        "......b_text_2.txt<br>\r\n",
        "\r\n",
        "\r\n",
        "When running a machine learning experiment, it is a best practice to divide your dataset into three splits: train, validation, and test. The Stack Overflow dataset has already been divided into train and test, but it lacks a validation set. Create a validation set using an 80:20 split of the training data by using the validation_split argument below.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCVRgr-XhlIQ",
        "outputId": "d3bd1322-1e09-4607-eacf-d8ddcdae33e1"
      },
      "source": [
        "batch_size = 32\r\n",
        "seed = 42\r\n",
        "\r\n",
        "raw_train_ds = preprocessing.text_dataset_from_directory(\r\n",
        "                                                 train_dir,\r\n",
        "                                                 labels = \"inferred\",\r\n",
        "                                                 batch_size=batch_size,\r\n",
        "                                                 # fraction of data to \r\n",
        "                                                 #  reserve for validation. \r\n",
        "                                                 validation_split=0.2, \r\n",
        "                                                 # Return back 'train' subset\r\n",
        "                                                 #  but in batches\r\n",
        "                                                 subset='training',\r\n",
        "                                                 seed =2 \r\n",
        "                                                 )\r\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "limn3VFaifa0",
        "outputId": "778be9fc-d192-4416-ed38-62d42f635ab2"
      },
      "source": [
        "type(raw_train_ds)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ul0T53iozh"
      },
      "source": [
        "# Dataset.take(n) object is iterable.\r\n",
        "# Iterate over the dataset and print out a few examples,\r\n",
        "#  to get a feel for the data.\r\n",
        "# take(n): Reads n batches\r\n",
        "\r\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\r\n",
        "  print(text_batch.numpy().shape)  # 32: batch_size\r\n",
        "                                   # Change batch_size to see how it changes\r\n",
        "  for i in range(10):\r\n",
        "    print(\"Question: \", text_batch.numpy()[i])\r\n",
        "    print(\"Label:\", label_batch.numpy()[i])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z_K3qB_iu50",
        "outputId": "2e5c6439-6ecc-4848-f22c-e2ec829ed487"
      },
      "source": [
        "# Get class_names in the dataset:\r\n",
        "for i, label in enumerate(raw_train_ds.class_names):\r\n",
        "  print(\"Label\", i, \"corresponds to\", label)\r\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to csharp\n",
            "Label 1 corresponds to java\n",
            "Label 2 corresponds to javascript\n",
            "Label 3 corresponds to python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jW_rYBmi4P9",
        "outputId": "1aefaa16-72d7-4c14-9ab4-8de59ca7dd96"
      },
      "source": [
        "# From train_dir pick-up remaining validation\r\n",
        "#  dataset but in batches:\r\n",
        "\r\n",
        "raw_validation_ds = preprocessing.text_dataset_from_directory(\r\n",
        "                                      train_dir,\r\n",
        "                                      batch_size=batch_size,\r\n",
        "                                      validation_split=0.2,\r\n",
        "                                      # Return validation data\r\n",
        "                                      # but in batches\r\n",
        "                                      subset='validation'\r\n",
        "                                  )\r\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiV1uP-KEian",
        "outputId": "b25ec739-4bef-4e22-eda8-521adeeee0b3"
      },
      "source": [
        "test_dir = dataset_dir/'test'\r\n",
        "\r\n",
        "raw_test_ds = preprocessing.text_dataset_from_directory(\r\n",
        "                              test_dir,\r\n",
        "                              batch_size=batch_size\r\n",
        "                              )\r\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erhhZqsQHV5V"
      },
      "source": [
        "### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW1XNohSHaUe"
      },
      "source": [
        "#### Using `preprocessing.TextVectorization` layer. Its [full syntax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) is:\r\n",
        "\r\n",
        "`tf.keras.layers.experimental.preprocessing.TextVectorization(\r\n",
        "    max_tokens=None, standardize=LOWER_AND_STRIP_PUNCTUATION,\r\n",
        "    split=SPLIT_ON_WHITESPACE, ngrams=None, output_mode=INT,\r\n",
        "    output_sequence_length=None, pad_to_max_tokens=True, vocabulary=None, **kwargs\r\n",
        ")\r\n",
        "`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmeY-1dzHUPf"
      },
      "source": [
        "Next, we will standardize, tokenize, and vectorize the data using the preprocessing.TextVectorization layer.\r\n",
        "\r\n",
        "> Standardization refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset.\r\n",
        "\r\n",
        "> Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words by splitting on whitespace).\r\n",
        "\r\n",
        "> Vectorization refers to converting tokens into numbers so they can be fed into a neural network.\r\n",
        "\r\n",
        "All of these tasks can be accomplished with this layer. You can learn more about each of these in the API doc.\r\n",
        "\r\n",
        "> The default standardization converts text to lowercase and removes punctuation.\r\n",
        "\r\n",
        "> The default tokenizer splits on whitespace.\r\n",
        "\r\n",
        "> The default vectorization mode is int. This outputs integer indices (one per token). This mode can be used to build models that take word order into account. You can also use other modes, like binary, to build bag-of-word models.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOG9KZXx7Cz"
      },
      "source": [
        "VOCAB_SIZE = 10000\r\n",
        "MAX_SEQUENCE_LENGTH = 250\r\n",
        "\r\n",
        "# Instantiate TextVectorization class\r\n",
        "int_vectorize_layer = TextVectorization(\r\n",
        "                                         max_tokens=VOCAB_SIZE,\r\n",
        "                                         output_mode='int',\r\n",
        "                                         output_sequence_length=MAX_SEQUENCE_LENGTH\r\n",
        "                                        )\r\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4G44ZLSyUZ2"
      },
      "source": [
        "#binary_vectorize_layer = TextVectorization(\r\n",
        "#                                            max_tokens=VOCAB_SIZE,\r\n",
        "#                                            output_mode='binary'\r\n",
        "#                                            )"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6NQdIwmyZdF"
      },
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\r\n",
        "train_text = raw_train_ds.map(lambda text, labels: text)\r\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69BLH-gpI_F1"
      },
      "source": [
        "# 'adapt' or 'fit' over 'int_vectorize_layer'\r\n",
        "#   object. 'adpat' fits the state of the preprocessing\r\n",
        "#     layer to the dataset.\r\n",
        "\r\n",
        "int_vectorize_layer.adapt(\r\n",
        "                          # The data to train on. \r\n",
        "                          #   It can be passed either as\r\n",
        "                          #     a tf.data Dataset, as a NumPy array\r\n",
        "                           train_text # \r\n",
        "                          )\r\n",
        "#binary_vectorize_layer.adapt(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3Yi-roZK-d8",
        "outputId": "16b2c68b-151b-41f6-fde3-1a692c382715"
      },
      "source": [
        "int_vectorize_layer.get_vocabulary()[:4]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCluJyliLghk",
        "outputId": "0e90baae-8ed2-49b9-a0c7-1cff8ecee64a"
      },
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset\r\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\r\n",
        "first_question, first_label = text_batch[0], label_batch[0]\r\n",
        "print(\"Question\", first_question)\r\n",
        "print(\"Label\", first_label)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question tf.Tensor(b'\"blank8 why is my solution faster than the neat solution? (hackerrank chocolate feast) edit: simplified my solution..edit: removed opinion based secondary question...background: atarted learning blank a week or two ago using hackerranks problems as exercises and stackoverflow search + google as my teacher, i\\'ve had some limited experience learning other languages...i did the exercise my own \"\"noobish learner way\"\" which i can\\'t help but feel is a \"\"botched job\"\" when i see \"\"neat &amp; short\"\" solutions...however, when submitting both solutions one after another a couple of times i found the \"\"neat\"\" solution was quite a bit slower. ..i vaguely remember something about % operations being costly, is mine faster because of no % operations or is there more to it than just that?..exercise: https://www.hackerrank.com/challenges/chocolate-feast..neat solution from discussion:..import blank.io.*;.import blank.util.*;..public class solution {.    static int cc; .    public static void main(string[] args) {.        scanner in = new scanner(system.in);.        int t,n,c,m,r;.            t = in.nextint();.            while(t--&gt;0){.             n = in.nextint();.            c = in.nextint();.             m = in.nextint();.                r=n/c;.                cc=r;..                    while(r&gt;=m){.                        cc=cc+r/m;.                        r=r%m+r/m;.                    }..                system.out.println(cc); .            }..    }.}...my solution:..import blank.io.*;.import blank.util.*;..public class solution {..    public static void main(string[] args) {..        scanner sc = new scanner(system.in);.        int t = integer.parseint(sc.nextline());    //t = number of test cases.        int[][] tc = readinput(sc, t);              //tc[t][0] = money. tc[t][1] = price. tc[t][2] = wrappers per free bar..        for (int i = 0; i&lt;t; i++){                  //loop for all test cases.            int choc = calcchoc(tc,i);              //work out how much choc can be bought.            system.out.println(choc);               //print result for the test case.        }.    }.    //calculate how much choc he can buy with m $ at p price with w wrappers needed for a free bar.    public static int calcchoc(int[][] tc,int i){..        int m = tc[i][0];       //money he has.        int p = tc[i][1];       //price of choc.        int w = tc[i][2];       //wrappers per free bar..        int bars = m/p;         //how many bars he can buy initially.        int wrappers = bars;    //each bar is a wrapper from initial purpose..        //loop to turn in all wrappers while it is possible to do so.        while (w&lt;=wrappers){..            int barsfromturnin = wrappers/w;                //bars from turning in current wrappers..            bars = bars + barsfromturnin;                   //new bar count.            wrappers = wrappers - (barsfromturnin * (w-1)); //wrapper count reduced by amount of wrappers turned in -1 wrapper per bar recieved from turn in...            if (w==1){ //break out of infinite loop when you get 1 bar for 1 wrapper!.                system.out.print(\"\"infinite bars, exiting infinite loop at bars = \"\");.                break;.            }.        }.        return bars;.    }.    //read input for each test case and make 2d array of the info.    public static int[][] readinput(scanner sc, int t){..        int[][] input = new int[t][3];..        for (int i = 0; i&lt;t; i++){.            string[] inputline = sc.nextline().split(\"\" \"\");..            input[i][0] = integer.parseint(inputline[0]);.            input[i][1] = integer.parseint(inputline[1]);.            input[i][2] = integer.parseint(inputline[2]);.        }.        return input;.    }.}\"\\n', shape=(), dtype=string)\n",
            "Label tf.Tensor(1, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsCV4yZYKH7Q",
        "outputId": "cc17e9a3-513d-489a-8dc3-b76f1ae4c447"
      },
      "source": [
        "# Expand \r\n",
        "type(first_question)\r\n",
        "print(\"\\n--------------\\n\")\r\n",
        "first_question.get_shape()\r\n",
        "print(\"\\n--------------\\n\")\r\n",
        "t = tf.expand_dims(first_question,-1)\r\n",
        "t.get_shape()\r\n",
        "print(\"\\n--------------\\n\")\r\n",
        "print(t)\r\n",
        "print(\"\\n--------------\\n\")\r\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------\n",
            "\n",
            "tf.Tensor([b'\"blank8 why is my solution faster than the neat solution? (hackerrank chocolate feast) edit: simplified my solution..edit: removed opinion based secondary question...background: atarted learning blank a week or two ago using hackerranks problems as exercises and stackoverflow search + google as my teacher, i\\'ve had some limited experience learning other languages...i did the exercise my own \"\"noobish learner way\"\" which i can\\'t help but feel is a \"\"botched job\"\" when i see \"\"neat &amp; short\"\" solutions...however, when submitting both solutions one after another a couple of times i found the \"\"neat\"\" solution was quite a bit slower. ..i vaguely remember something about % operations being costly, is mine faster because of no % operations or is there more to it than just that?..exercise: https://www.hackerrank.com/challenges/chocolate-feast..neat solution from discussion:..import blank.io.*;.import blank.util.*;..public class solution {.    static int cc; .    public static void main(string[] args) {.        scanner in = new scanner(system.in);.        int t,n,c,m,r;.            t = in.nextint();.            while(t--&gt;0){.             n = in.nextint();.            c = in.nextint();.             m = in.nextint();.                r=n/c;.                cc=r;..                    while(r&gt;=m){.                        cc=cc+r/m;.                        r=r%m+r/m;.                    }..                system.out.println(cc); .            }..    }.}...my solution:..import blank.io.*;.import blank.util.*;..public class solution {..    public static void main(string[] args) {..        scanner sc = new scanner(system.in);.        int t = integer.parseint(sc.nextline());    //t = number of test cases.        int[][] tc = readinput(sc, t);              //tc[t][0] = money. tc[t][1] = price. tc[t][2] = wrappers per free bar..        for (int i = 0; i&lt;t; i++){                  //loop for all test cases.            int choc = calcchoc(tc,i);              //work out how much choc can be bought.            system.out.println(choc);               //print result for the test case.        }.    }.    //calculate how much choc he can buy with m $ at p price with w wrappers needed for a free bar.    public static int calcchoc(int[][] tc,int i){..        int m = tc[i][0];       //money he has.        int p = tc[i][1];       //price of choc.        int w = tc[i][2];       //wrappers per free bar..        int bars = m/p;         //how many bars he can buy initially.        int wrappers = bars;    //each bar is a wrapper from initial purpose..        //loop to turn in all wrappers while it is possible to do so.        while (w&lt;=wrappers){..            int barsfromturnin = wrappers/w;                //bars from turning in current wrappers..            bars = bars + barsfromturnin;                   //new bar count.            wrappers = wrappers - (barsfromturnin * (w-1)); //wrapper count reduced by amount of wrappers turned in -1 wrapper per bar recieved from turn in...            if (w==1){ //break out of infinite loop when you get 1 bar for 1 wrapper!.                system.out.print(\"\"infinite bars, exiting infinite loop at bars = \"\");.                break;.            }.        }.        return bars;.    }.    //read input for each test case and make 2d array of the info.    public static int[][] readinput(scanner sc, int t){..        int[][] input = new int[t][3];..        for (int i = 0; i&lt;t; i++){.            string[] inputline = sc.nextline().split(\"\" \"\");..            input[i][0] = integer.parseint(inputline[0]);.            input[i][1] = integer.parseint(inputline[1]);.            input[i][2] = integer.parseint(inputline[2]);.        }.        return input;.    }.}\"\\n'], shape=(1,), dtype=string)\n",
            "\n",
            "--------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36xkgUasUOvI",
        "outputId": "83e18986-4f99-41c5-d244-0cb24f439d8b"
      },
      "source": [
        "\r\n",
        "int_vectorize_layer(t)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
              "array([[   1,  111,    6,   23,  299, 1787,  198,    2, 3623,  299, 7826,\n",
              "           1,    1,  805, 2568,   23,    1, 1218, 3892,  364, 4145,    1,\n",
              "           1,  661,   16,    5,  981,   45,  121, 1881,   47,    1,  742,\n",
              "          36, 9987,    8, 1982,  322,  662,   36,   23, 2362,  195,  543,\n",
              "          83, 2693, 2609,  661,  144,    1,  411,    2, 1371,   23,  657,\n",
              "           1, 6520,   84,   66,    3,  166,  104,   26, 1182,    6,    5,\n",
              "           1, 1639,   44,    3,  189, 3623,  519, 1135,    1,   44, 5468,\n",
              "         280, 1272,   71,  156,  157,    5, 1759,    9,  331,    3,  227,\n",
              "           2, 3623,  299,  115,  810,    5,  547, 3833,    3,    1, 2371,\n",
              "         146,  202, 1195,  289,    1,    6, 2179, 1787,  193,    9,  136,\n",
              "        1195,   45,    6,   67,  181,    4,   11,  198,  106,    1,    1,\n",
              "         299,   31,    1, 2216, 1924,   29,  299,   53,   28, 2081,   22,\n",
              "          53,   42,  170,  154,  256,    7,   15,  453,   28,    1,  237,\n",
              "        2698,    1,  134, 2698,  131, 2698,  323, 2698,    1,    1,    1,\n",
              "           1,    1,    1,   23,    1, 2216, 1924,   29,  299,   22,   53,\n",
              "          42,  170,  154,  256, 1360,   15,  453,   28,  237,    1,  237,\n",
              "          68,    9,  196,  807,   28, 7167,    1,  237,    1, 1364,    1,\n",
              "         562,    1, 4406,  735, 1820,  761,   12,   28,    3,   19,    1,\n",
              "           3,  123,   12,   73,  196,  807,   28,    1,    1,  139,   94,\n",
              "          24,  406,    1,   35,   33, 5921,    1,   75,  128,   12,    2,\n",
              "         196,  133,  588,   24,  406,    1,  603,   35, 3728,   21,  323,\n",
              "          59,  376,  562,   21,  445, 4406,  816,   12,    5, 1820,  761,\n",
              "          22,   53,   28,    1,    1,    3,   28,  323]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vBeok3Ly0op"
      },
      "source": [
        "def int_vectorize_text(text, label):\r\n",
        "  text = tf.expand_dims(text, -1)\r\n",
        "  return int_vectorize_layer(text) , label"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ7zWdNwy6VH",
        "outputId": "f4c4f8aa-1bc3-4b3a-9ac5-9723a3b85309"
      },
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) \r\n",
        "#  from the dataset\r\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\r\n",
        "first_question, first_label = text_batch[0], label_batch[0]\r\n",
        "print(\"Question\", first_question)\r\n",
        "print(\"Label\", first_label)\r\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question tf.Tensor(b'\"simple program not giving desired output i am starting to learn blank and i have a simple program to request two numbers from the user and add them together. when i run my program , i get asked for the first number , i type it in and that\\'s it, the program doesn\\'t go any further. i am running it in visual studio..can anyone tell me what i\\'m doing wrong? ..using system;..namespace coding.{.    class program.    {.        static void main(string[] args).        {..            int number1;.            int number2;.            int result;...            console.writeline(\"\"enter first  number to be calculated\"\");.            number1 = convert.toint32(console.readline());...            console.writeline(\"\"enter second  number to be calculated\"\");.            number2 = convert.toint32(console.readline());..            result = number1 + number2;.            console.writeline(\"\"the total is\"\" + \"\" \"\" + result);.        }.    }.}...result screenshot\"\\n', shape=(), dtype=string)\n",
            "Label tf.Tensor(0, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z32g2G2cWwXy",
        "outputId": "ab49fa5a-3ef4-4002-b2c9-ef4c2a888dcb"
      },
      "source": [
        "print(\"'int' vectorized question:\",\r\n",
        "      int_vectorize_text(first_question, first_label)[0])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'int' vectorized question: tf.Tensor(\n",
            "[ 241   86   20  696 1050  126    3   34  753    4  964   16    8    3\n",
            "   17    5  241   86    4  524  121  183   31    2   99    8  125  191\n",
            "  947   44    3  138   23   86    3   41  912   12    2   98   68    3\n",
            "  122   11    7    8  712   11    2   86  178  301   76 1533    3   34\n",
            "  309   11    7  821    1  285  412   74   55   52  210  151   47 4458\n",
            "  859   29   86   53   42  170  154   28 1991   28 2177   28  128 2206\n",
            "   98   68    4   33 2082 1991 1965 2206  199   68    4   33 2082 2177\n",
            " 1965  128 1991 2177 2722  267    6  128  128 2570    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJtNmRyRy-db",
        "outputId": "a7b41182-5b64-44c3-d638-f0722379b461"
      },
      "source": [
        "print(\"'int' vectorized question:\",\r\n",
        "      int_vectorize_text(first_question, first_label)[0])\r\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'int' vectorized question: tf.Tensor(\n",
            "[[ 241   86   20  696 1050  126    3   34  753    4  964   16    8    3\n",
            "    17    5  241   86    4  524  121  183   31    2   99    8  125  191\n",
            "   947   44    3  138   23   86    3   41  912   12    2   98   68    3\n",
            "   122   11    7    8  712   11    2   86  178  301   76 1533    3   34\n",
            "   309   11    7  821    1  285  412   74   55   52  210  151   47 4458\n",
            "   859   29   86   53   42  170  154   28 1991   28 2177   28  128 2206\n",
            "    98   68    4   33 2082 1991 1965 2206  199   68    4   33 2082 2177\n",
            "  1965  128 1991 2177 2722  267    6  128  128 2570    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nek59tjoK8We"
      },
      "source": [
        "## New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbR_fFwFfAZ3"
      },
      "source": [
        "dataset, info = tfds.load(\r\n",
        "                           'imdb_reviews',\r\n",
        "                            with_info=True,\r\n",
        "                            as_supervised=True\r\n",
        "                          )\r\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KasrLWBxti1I",
        "outputId": "5feb02d0-f256-401d-8bb5-6bdb31d50d3a"
      },
      "source": [
        "type(dataset)    # dict\r\n",
        "dataset.keys()   # _keys(['test', 'train', 'unsupervised'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['test', 'train', 'unsupervised'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjVYxthfe5u1"
      },
      "source": [
        "train_dataset, test_dataset = dataset['train'], dataset['test']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AKwLI37ts4l",
        "outputId": "5bc1b512-28af-4c9b-fa08-29400a41011e"
      },
      "source": [
        "type(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYPStpOffqa",
        "outputId": "9bfbaa2d-400f-48fd-999e-d55b8a4214ce"
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDz4zhKLvhtz"
      },
      "source": [
        "for example, label in train_dataset.take(2):\r\n",
        "  print('text: ', example.numpy())\r\n",
        "  print('label: ', label.numpy())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7r8zoJhfh3J"
      },
      "source": [
        "BUFFER_SIZE = 10000\r\n",
        "BATCH_SIZE = 64      # Try 2 and see what happens\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2oUXxoNv1ep"
      },
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiIv4g-03N6V"
      },
      "source": [
        "# Creates a `Dataset` with at most `count` elements from this dataset.\r\n",
        "help(train_dataset.take)\r\n",
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.take(3)\r\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtiyQFMyemv"
      },
      "source": [
        "# Each take is of batch size\r\n",
        "for example, label in train_dataset.take(3):\r\n",
        "  print('texts: ', example.numpy().shape)\r\n",
        "  print('texts: ', example.numpy()[:4])\r\n",
        "  print()\r\n",
        "  print('labels: ', label.numpy()[:4])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umAmsi-_v89a"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization\r\n",
        "# Text vectorization layer.\r\n",
        "VOCAB_SIZE=1000\r\n",
        "\r\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\r\n",
        "                                                                         max_tokens=VOCAB_SIZE\r\n",
        "                                                                       )\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYuiIvSJ6evX"
      },
      "source": [
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqcyclv6qfw"
      },
      "source": [
        "encoder.get_vocabulary()[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vf9dfU8jj5"
      },
      "source": [
        "help(encoder(example))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8h4tgjU_jPF"
      },
      "source": [
        "example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJPR-HLF6roH"
      },
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\r\n",
        "encoded_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiFNN59V8BlI"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    encoder,\r\n",
        "    tf.keras.layers.Embedding(\r\n",
        "        input_dim=len(encoder.get_vocabulary()),\r\n",
        "        output_dim=64,\r\n",
        "        # Use masking to handle the variable sequence lengths\r\n",
        "        mask_zero=True),\r\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1)\r\n",
        "])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xXs8_h-_8Rw",
        "outputId": "19373db1-704b-4eb1-b51b-38e19efac787"
      },
      "source": [
        "print([layer.supports_masking for layer in model.layers])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJf5CWVSACRD"
      },
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\r\n",
        "               'were out of this world. I would recommend this movie.')\r\n",
        "predictions = model.predict(np.array([sample_text]))\r\n",
        "print(predictions[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1TIKlp6AG_D",
        "outputId": "13b18114-4d61-4305-c267-840fa1f03cd2"
      },
      "source": [
        "# predict on a sample text with padding\r\n",
        "\r\n",
        "padding = \"the \" * 2000\r\n",
        "predictions = model.predict(np.array([sample_text, padding]))\r\n",
        "print(predictions[0])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0159057]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfXweFWVAN8k"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
        "              metrics=['accuracy'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enLq6m8FAdq6"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10,\r\n",
        "                    validation_data=test_dataset, \r\n",
        "                    validation_steps=30)   \r\n",
        "# Each epoch takes 690 secs on TPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okkIQN3iAgTn"
      },
      "source": [
        "def plot_graphs(history, metric):\r\n",
        "  plt.plot(history.history[metric])\r\n",
        "  plt.plot(history.history['val_'+metric], '')\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(metric)\r\n",
        "  plt.legend([metric, 'val_'+metric])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lj4Pw6BFMa"
      },
      "source": [
        "dataset3 = tf.data.Dataset.from_tensors(\r\n",
        "                                         (\r\n",
        "                                           tf.random.uniform([4]),    # shape [4]\r\n",
        "                                           tf.random.normal([4, 6], mean=1.5,stddev=2.2) # [4,100]\r\n",
        "                                          )\r\n",
        "                                        )"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}