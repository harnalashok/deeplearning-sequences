{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.simple_rnn_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4Lytl3Y3JzaDdODISaO3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning-sequences/blob/main/2_simple_rnn_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg_Jjf8nfago"
      },
      "source": [
        "\"\"\"\r\n",
        "Last amended: 07th March, 2021\r\n",
        "My folder: /home/ashok/Documents/8.rnn\r\n",
        "           github/harnalashok/\r\n",
        "Ref: Page\r\n",
        "\r\n",
        "Objectives:\r\n",
        "        i)   To use SimpleRNN for Sentiment analysis\r\n",
        "        ii)  To understand structure of Embedding layer\r\n",
        "\t    iii) To perform tokenization, see file:\r\n",
        "             8.rnn/3.keras_tokenizer_class.py OR file\r\n",
        "             8.rnn/0.document_to_id_conversion.py\r\n",
        "\t         And a quick note at the end of this code.\r\n",
        "\r\n",
        "\"\"\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSOqIGBOg3O2"
      },
      "source": [
        "\r\n",
        "# 1.0 Call libraries\r\n",
        "%reset -f\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# 1.1 Import module imdb & other keras modules\r\n",
        "from tensorflow.keras.datasets import imdb\r\n",
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\r\n",
        "\r\n",
        "# 1.2 Misc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiSHMqm0iCMB"
      },
      "source": [
        "# 1.1\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guonkes-g_Rm"
      },
      "source": [
        "# 2.1 Define some constants\r\n",
        "max_vocabulary = 10000        # words\r\n",
        "max_len_review = 500          # words"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuhUDFofhENs",
        "outputId": "5a61e733-bea8-4805-dbd9-4c8243721e85"
      },
      "source": [
        "# 2.2 About imdb module\r\n",
        "help(imdb)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package tensorflow.keras.datasets.imdb in tensorflow.keras.datasets:\n",
            "\n",
            "NAME\n",
            "    tensorflow.keras.datasets.imdb - IMDB sentiment classification dataset.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/keras/datasets/imdb/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUx84V6hMBi",
        "outputId": "fbebdaa5-e9f5-4cd9-e814-0a3c24d1afc8"
      },
      "source": [
        "# 2.3 Get imdb reviews. Limit vocabulary to size max_vocabulary\r\n",
        "#      imdb reviews will be downloaded unless available at ~/.keras/datasets\r\n",
        "# ************\r\n",
        "#      See comments at the end as to how to quickly convert text to integers\r\n",
        "# ************\r\n",
        "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_vocabulary)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KOezprWhchy",
        "outputId": "cafab605-9a94-493f-9497-f510e977c438"
      },
      "source": [
        "# 2.4 Our downloaded data file is here:\r\n",
        "\r\n",
        "!ls -la /root/.keras/datasets"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 17064\n",
            "drwxr-xr-x 2 root root     4096 Mar  7 07:11 .\n",
            "drwxr-xr-x 3 root root     4096 Mar  7 07:11 ..\n",
            "-rw-r--r-- 1 root root 17464789 Mar  7 07:11 imdb.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6-bOkXIhnHG",
        "outputId": "7042adfe-66de-43ee-9bb8-074b2402339b"
      },
      "source": [
        "# 2.5 About data\r\n",
        "type(x_train)      # numpy.ndarray\r\n",
        "x_train.shape      # (25000,)  Total 25000 reviews\r\n",
        "x_test.shape       # (25000,)  Total 25000 reviews\r\n",
        "y_train.shape      # (25000,)  Total 25000 pos/neg labels\r\n",
        "y_test.shape       # (25000,)  Total 25000 pos/neg labels"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKAx_Acph3WK",
        "outputId": "e3570a71-da10-46cc-a72f-913c2bba48f1"
      },
      "source": [
        "# 2.5.1\r\n",
        "x_train[:2]       # Have a look at two documents\r\n",
        "print(\"\\n\\n------------\\n\\n\")\r\n",
        "y_train[:4]       # array([1, 0, 0, 1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkjJTYkVh7sB",
        "outputId": "42235481-0fcb-4d8f-a7ed-50421d2851f5"
      },
      "source": [
        "# 2.5.2 Every comment has different number of words\r\n",
        "len(x_train[1])     # 189\r\n",
        "print(\"\\n\\n------------\\n\\n\")\r\n",
        "len(x_train[10])    # 450"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEzLFzoUikc6"
      },
      "source": [
        "# 2.6 Check max and min length of reviews\r\n",
        "maxLen = 0         # Start with a low number\r\n",
        "minLen = 200       # Start with a high number\r\n",
        "for i in range(x_train.shape[0]):\r\n",
        "    if maxLen < len(x_train[i]):\r\n",
        "        maxLen = len(x_train[i])\r\n",
        "    if minLen > len(x_train[i]):\r\n",
        "        minLen = len(x_train[i])\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS6d0k59i4Ob",
        "outputId": "ec4a23cc-3303-47c3-8b29-50126bfb2936"
      },
      "source": [
        "# 2.6.1\r\n",
        "maxLen         # 2494\r\n",
        "minLen         # 11"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2494"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIbZr7Xai7NF"
      },
      "source": [
        "# 2.7 We want to pad all sequences to max_len_review size.\r\n",
        "#     Reviews more in size will be truncated and less in\r\n",
        "#     size will be padded with zeros\r\n",
        "# help(sequence.pad_sequences)\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3DzP9bfjAhU"
      },
      "source": [
        "# 2.7.1 Pad x_train sequences\r\n",
        "\r\n",
        "x_train = sequence.pad_sequences(\r\n",
        "                                 x_train,   # A list of lists where each inner\r\n",
        "                                            # list is a sequence, Or,\r\n",
        "                                            # An array of lists with each\r\n",
        "                                            #  list being a sequence\r\n",
        "                                 maxlen = max_len_review,\r\n",
        "                                 padding = 'pre'\r\n",
        "                                 )\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XK2qcxHjKpo",
        "outputId": "a0261645-096f-42c2-d0a9-15fa4c648886"
      },
      "source": [
        "# 2.7.2 Recheck again:\r\n",
        "\r\n",
        "type(x_train)          # numpy.ndarray\r\n",
        "print(\"\\n\\n------------\\n\\n\")\r\n",
        "x_train.shape          # (25000, 500) Each sequence becomes one row\r\n",
        "print(\"\\n\\n------------\\n\\n\")\r\n",
        "len(x_train[1])     # 189\r\n",
        "print(\"\\n\\n------------\\n\\n\")\r\n",
        "len(x_train[10])    # 450\r\n",
        "\r\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fn_mpcgjQpN"
      },
      "source": [
        "# 3.0 Model now\r\n",
        "model = Sequential()\r\n",
        "# 3.1 Embedding layer\r\n",
        "model.add(Embedding(max_vocabulary,            # Decides number of input neurons\r\n",
        "                    32,                        # Decides number of neurons in hidden layer\r\n",
        "                    input_length= max_len_review) # (optional) Decides how many times\r\n",
        "                                                  # RNN should loop around\r\n",
        "                                                  # If omitted, decided autoamtically\r\n",
        "                                                  # during 'model.fit()' by considering\r\n",
        "                                                  # x_train.shape[1]\r\n",
        "                    )\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcM3STw5jovc",
        "outputId": "7ff2ac6e-351d-448f-e2a0-6e226ea37fb1"
      },
      "source": [
        "# 3.2\r\n",
        "# It is instructive to see number of parameters\r\n",
        "#  in the summary. This tells us about the Embedding\r\n",
        "#   layer as being two layered network with no of neurons\r\n",
        "#    as max_vocabulary and output (hidden) layer with 32 neurons\r\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           320000    \n",
            "=================================================================\n",
            "Total params: 320,000\n",
            "Trainable params: 320,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVEZdt8Cj0Bf"
      },
      "source": [
        "# 3.3 Ideally we should be adding not one RNN but as many RNNs as\r\n",
        "#     there are timesteps ie sequence length or 'max_len_review'.\r\n",
        "#     But we add just one and perform internal looping. Note that\r\n",
        "#     internal weights and hence LSTM parameters remain same from one\r\n",
        "#     'timestep' to another 'timestep'. You can verify this by\r\n",
        "#     changing the value of max_len_review and seein that number\r\n",
        "#     of parameters in the model summary after adding the following\r\n",
        "#     do not change.\r\n",
        "\r\n",
        "model.add(SimpleRNN(32,\r\n",
        "                    return_sequences = False   # Make it True\r\n",
        "                                               # And add layer #3.4\r\n",
        "                    )\r\n",
        "                    )   # Output\r\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxNTayulj4To"
      },
      "source": [
        "# 3.4 JUMP FOLLOWING UNLESS YOU WANT 'RNN' ABOVE 'RNN'. IT WORKS.\r\n",
        "#     BUT TAKES TIME.\r\n",
        "# 3.4 Make return_sequences = True in 3.3 above, before you add\r\n",
        "#     the following layer with return_sequences = False. Else JUMP it.\r\n",
        "#     ACCURACY IS SOMEWHAT MORE\r\n",
        "\r\n",
        "model.add(SimpleRNN(\r\n",
        "                    32,\r\n",
        "                    return_sequences = False   # Make return_sequences = True\r\n",
        "                                               # in earlier RNN for this to work\r\n",
        "                    )\r\n",
        "                    )   # Output\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "ObWQw8fnkHHz",
        "outputId": "3cce5416-40a7-4f5b-a489-961040b0d6d2"
      },
      "source": [
        "\"\"\"\r\n",
        "Why SimpleRNN adds 2080 parameters?\r\n",
        "    input_features * output_features = 32 * 32  = 1024\r\n",
        "    state_t * output_features        = 32 * 32  = 1024\r\n",
        "    Bias                                            32\r\n",
        "    Total                                         2080\r\n",
        "This total is INDEPENDENT of sequence length or timesteps.\r\n",
        "\"\"\"\r\n",
        "model.summary()     # Why SimpleRNN adds 2080 parameters?\r\n",
        "                    # input_features * output_features = 32 * 32  = 1024\r\n",
        "                    # state_t * output_features        = 32 * 32  = 1024\r\n",
        "                    # Bias                                            32\r\n",
        "                    # Total                                         2080\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWhy SimpleRNN adds 2080 parameters?\\n    input_features * output_features = 32 * 32  = 1024\\n    state_t * output_features        = 32 * 32  = 1024\\n    Bias                                            32\\n    Total                                         2080\\nThis total is INDEPENDENT of sequence length or timesteps.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
            "=================================================================\n",
            "Total params: 322,080\n",
            "Trainable params: 322,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWoDn5akkNpz",
        "outputId": "20e2ec7c-1a03-42c6-f4f6-2551a052e4e8"
      },
      "source": [
        "# 3.5\r\n",
        "model.add(Dense(1, activation = 'sigmoid'))\r\n",
        "model.summary()\r\n",
        "#help(model.compile)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3quucG2SkOMb"
      },
      "source": [
        "# 3.5.1\r\n",
        "model.compile(loss = 'binary_crossentropy',\r\n",
        "              optimizer = 'rmsprop',\r\n",
        "              metrics = ['acc'])\r\n",
        "\r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtfzEt0fkaur",
        "outputId": "7c9f283b-6721-49c1-88d2-0aa2524fecb3"
      },
      "source": [
        "# 4.0\r\n",
        "epochs = 10\r\n",
        "start = time.time()\r\n",
        "history = model.fit(x_train,\r\n",
        "                    y_train,\r\n",
        "                    batch_size = 32,             # Number of samples per gradient update\r\n",
        "                    validation_split = 0.2,      # Fraction of training data to be used as validation data\r\n",
        "                    epochs = epochs,\r\n",
        "                    shuffle = True,              # Shuffle training data before each epoch\r\n",
        "                    verbose =1\r\n",
        "                    )\r\n",
        "end = time.time()\r\n",
        "(end-start)/60\r\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.6329 - acc: 0.6131 - val_loss: 0.3881 - val_acc: 0.8306\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.3580 - acc: 0.8515 - val_loss: 0.3754 - val_acc: 0.8458\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.2850 - acc: 0.8927 - val_loss: 0.3277 - val_acc: 0.8652\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.2463 - acc: 0.9054 - val_loss: 0.3404 - val_acc: 0.8566\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.2071 - acc: 0.9225 - val_loss: 0.3489 - val_acc: 0.8592\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.1738 - acc: 0.9352 - val_loss: 0.4282 - val_acc: 0.8450\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.1667 - acc: 0.9360 - val_loss: 0.5178 - val_acc: 0.8386\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.1267 - acc: 0.9523 - val_loss: 0.5153 - val_acc: 0.8140\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.0987 - acc: 0.9649 - val_loss: 0.5090 - val_acc: 0.8154\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.0676 - acc: 0.9770 - val_loss: 0.5371 - val_acc: 0.8126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.425282375017803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT54s0zkkgAu"
      },
      "source": [
        "# 5.0 Plot how network learns as per epochs\r\n",
        "def plot_learning_curve():\r\n",
        "    val_acc = history.history['val_acc']\r\n",
        "    tr_acc=history.history['acc']\r\n",
        "    epochs = range(1, len(val_acc) +1)\r\n",
        "    plt.plot(epochs,val_acc, 'b', label = \"Validation accu\")\r\n",
        "    plt.plot(epochs, tr_acc, 'r', label = \"Training accu\")\r\n",
        "    plt.title(\"Learning Curve: Training and validation accuracy\")\r\n",
        "    plt.legend()\r\n",
        "    plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX_kysPllAV8"
      },
      "source": [
        "# 5.1\r\n",
        "plot_learning_curve()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llzltoILlDU3"
      },
      "source": [
        "# 6.1 Get x_test padded\r\n",
        "x_test = sequence.pad_sequences(\r\n",
        "                                 x_test,   # A list of lists where each inner\r\n",
        "                                            # list is a sequence, Or,\r\n",
        "                                            # An array of lists with each\r\n",
        "                                            #  list being a sequence\r\n",
        "                                 maxlen = max_len_review,\r\n",
        "                                 padding = 'pre'\r\n",
        "                                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MiDxhiDlHw7"
      },
      "source": [
        "# 6.2 Predict now\r\n",
        "out = model.predict(x_test)\r\n",
        "out[out > 0.5]  = 1\r\n",
        "out[out <= 0.5] = 0\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7TSkQkVlM0z"
      },
      "source": [
        "# 6.3\r\n",
        "model.evaluate(x_test,y_test)\r\n",
        "# 7.3.1\r\n",
        "model.metrics_names        # ['loss', 'acc']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsyG3ONBliCU"
      },
      "source": [
        "############ I am done ################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsLsZBqrlpvz"
      },
      "source": [
        "\r\n",
        "###############################################################\r\n",
        "# Here is Quick text to integer conversion\r\n",
        "#  For more study, please see file: 3.keras_tokenizer_class.py\r\n",
        "###############################################################\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "texts = [\"Sun shines brightly  in June!\",\r\n",
        "         \"Star light shines on water?\",\r\n",
        "         \"Water is flowing.\",\r\n",
        "         \"Flowing water, shines\",\r\n",
        "         \"Sun is star?\",\r\n",
        "         \"World shines\",\r\n",
        "         \"Star also shines\",\r\n",
        "         \"water is life\",\r\n",
        "         \"Sun is energy\"]\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(texts)\r\n",
        "tokenizer.word_index       # Index is created based on word-frequencies\r\n",
        "                           # Most frequent word gets the least index\r\n",
        "tokenizer.texts_to_sequences(texts)\r\n",
        "#########\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}