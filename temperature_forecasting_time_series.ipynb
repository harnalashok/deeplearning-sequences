{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtO4VBmXq4wxHNWvmQq6sq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning-sequences/blob/main/temperature_forecasting_time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdneRZu9b6LV"
      },
      "outputs": [],
      "source": [
        "# Last amended: 26th July, 2019\n",
        "# My folder: /home/ashok/Documents/14.sensor_data\n",
        "# VM: lubuntu_deeplearning_I.vdi\n",
        "# Ref: Page 207, Chapter 6, Deep Learning with Python by Fracois Chollete\n",
        "# Download dataset from:\n",
        "# 1. Link to my google drive\n",
        "#  https://drive.google.com/file/d/1rnhlFKmmmhXqawaIBgjSTsqGrTLCUldV/view?usp=sharing\n",
        "# 2. Link to original datasource\n",
        "#  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objectives:\n",
        "#             i)  Working with timeseries data\n",
        "#             i)  Working with sensor data\n",
        "#                 (Data comes from many sensors)\n",
        "#             ii) Processing data to make it fit for modeling\n",
        "#            iii) Creating a data generator for training and validation\n",
        "#            iv)  Making predictions using\n",
        "#                   a) Fully connected dense model\n",
        "#                   b) GRU model\n",
        "#                   c) GRU model with dropouts\n",
        "#                   d) Stacked GRU models\n",
        "#                   e) Bidirectional RNN layer\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "huq-vVpRcH4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task"
      ],
      "metadata": {
        "id": "NJ616xsmcMxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will predict temperature\n",
        "# Sensor data is recorded every 10 minutes. So per-day we have:\n",
        "#   no of minutes:              24 * 60     =  1440\n",
        "#   no of 10 minutes interval: (24 * 60)/10 = 144 datapoints/per day\n",
        "#   no of data-points in 10 days: 1440"
      ],
      "metadata": {
        "id": "gdWgLHxRcL6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call libraries"
      ],
      "metadata": {
        "id": "q5YGPiuocaeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset all variables\n",
        "%reset -f\n",
        "\n",
        "# 1.0 Call libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time, gc"
      ],
      "metadata": {
        "id": "GfcUriAvcZnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "metadata": {
        "id": "9e-hx8pfdkcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to read csv data in numpy"
      ],
      "metadata": {
        "id": "a4csnTjzchOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Where is my data?\n",
        "data_dir = '/home/ashok/.keras/datasets/jena_climate'"
      ],
      "metadata": {
        "id": "Bn10kSZUcndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Join datapath with filename (intelligently)\n",
        "#     If you are on Windows, assign to fname full\n",
        "#     data path+ filename\n",
        "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
        "fname\n",
        "\n"
      ],
      "metadata": {
        "id": "krnBJRr2cjV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Read datafile, line by line\n",
        "# 1.3.1 First get a handle to file\n",
        "f = open(fname)   # open() default mode is text+read\n",
        "# 1.3.2 Use handle to read complete file\n",
        "data = f.read()"
      ],
      "metadata": {
        "id": "t_9bPtUhcu74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3.3 Close file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "LosNIABzctNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe read numpy data"
      ],
      "metadata": {
        "id": "v6RnleSAc5Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3.4 Observe data\n",
        "type(data)        # str\n",
        "data[0:200]      # Whole data is read as one string\n",
        "                 # Read first 200 characters of string\n",
        "                 # Note '\\n' at 196th character\n"
      ],
      "metadata": {
        "id": "wyz-ctvnc7xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 Look at data\n",
        "# 1.4.1 Split data on newline (\\n). So how many records?\n",
        "lines = data.split('\\n')    # Split each line at 'newline'\n",
        "type(lines)                 # list =>  All lines are in one list\n",
        "len(lines)                  # 420552\n",
        "type(lines[50])             # Each element of list is still a 'str'\n"
      ],
      "metadata": {
        "id": "Ekk9kqTGdChv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.2 Does any header exist? Check\n",
        "lines[0]                   # yes, it does\n",
        "lines[1]"
      ],
      "metadata": {
        "id": "2S5fHG7ldv_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.3 Extract header (field-names)\n",
        "header = lines[0].split(',')  # Split at each ','\n",
        "header"
      ],
      "metadata": {
        "id": "_nNljWDtdzWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.4 How many columns/fields?\n",
        "cols = len(header)\n",
        "cols             # 15"
      ],
      "metadata": {
        "id": "-k13-XlDd2Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4.5 Print first three rows.\n",
        "#       Note 10-minute gap in the\n",
        "#       observations\n",
        "lines[1:4]     # A list of 3 string elements\n",
        "len(lines)    # 420552 or header + 420551 data points"
      ],
      "metadata": {
        "id": "znBS9A3Ed3Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totalsamples = len(lines) - 1    # 420551 (exclude header)"
      ],
      "metadata": {
        "id": "YL-5VnyXe57C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data conversion"
      ],
      "metadata": {
        "id": "OelYdZt_faYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0 Convert all 420551 data points into a numpy array\n",
        "#     for processing\n",
        "\n",
        "# 2.1 First create a zero-valued 2D-array\n",
        "#      While creating zero-valued 2D-array, forget\n",
        "#        first column or time data\n",
        "#     So array size will be same as that of data\n",
        "#     We will also forget 1st column\n",
        "float_data = np.zeros((totalsamples, cols -1 ))  # Exclude 1st date/time col\n",
        "float_data.shape           # (420551,14)"
      ],
      "metadata": {
        "id": "-R-Z8gDAfYaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Fill this 2D-zero-valued array, row-by-row using for-loop\n",
        "# 2.2.1 First get an array of 420551 values\n",
        "#       0 ,1, 2, 3,...420550\n",
        "numbList=np.arange(len(lines) - 1 )\n",
        "numbList"
      ],
      "metadata": {
        "id": "tsERnYczuQbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2.2 See how a line is split in respective\n",
        "#       field values. We want split values to\n",
        "#       be an array. But after the split,\n",
        "#       they are a list\n",
        "x = lines[1].split(',')\n",
        "type(x)      # list"
      ],
      "metadata": {
        "id": "0qAOPV4DuVPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2.3\n",
        "x = np.asarray(x[1:], dtype = 'float32') # Exclude 1st date/time column\n",
        "type(x)\n",
        "x"
      ],
      "metadata": {
        "id": "1C-ZOWUZuYaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3  Fill up zero-array,row-by-row, with sensor data\n",
        "for i in numbList:      # ie uptil the last line\n",
        "    # 2.3 Now do this for all lines using for-loop\n",
        "    row = lines[i+1].split(',')     # i starts from 0 but we ignore header\n",
        "    # 2.3.1 'row' is a list. Select all but 1st element\n",
        "    row= row[1:]                    # Ignore the date column\n",
        "    values = np.asarray(row, dtype = 'float32')\n",
        "    float_data[i, :] = values      # Fill zero-array, row-by-row"
      ],
      "metadata": {
        "id": "HBIhlrsWuxSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3.2 Check\n",
        "float_data.shape     # (420551,14)\n",
        "\n",
        "# 2.3.2\n",
        "float_data[0]"
      ],
      "metadata": {
        "id": "iJzNzYHwu4cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting temperature"
      ],
      "metadata": {
        "id": "vo-sMzg8u7oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Let us plot temperature, the IInd column\n",
        "#    Check 'header', if you like\n",
        "# 3.1 Get column with index 1\n",
        "temp = float_data[:, 1]\n",
        "temp"
      ],
      "metadata": {
        "id": "4DOm1N_-u9ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 plot it. It is highly periodic\n",
        "plt.plot(range(len(temp)), temp)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "db3aC1udvOVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}