{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "time series modeling with attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwM+f+0wKmcw8K9W8vjLZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning-sequences/blob/main/time_series_modeling_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEV0_yrIPvMu"
      },
      "source": [
        "# Last amended: 9th July, 2021\n",
        "# Ref: https://github.com/philipperemy/keras-attention-mechanism\n",
        "# Objective:\n",
        "#            Use a multivariate time-series data to make prediction\n",
        "#            for future.\n",
        "#            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nx5gxR0aQ53"
      },
      "source": [
        "For example, given the stock prices data for last 10 days, as:<br> \n",
        "> <i>PrevClose,Open,High,Low,Last,VWAP,Volume_Turnover</i>, <b>Close</b> <br>\n",
        "Make predictions of <b>Close</b> price for the next day. Here, we use all <u>eight</u> features of the past to make predictions for future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtIiFZBwQGHm"
      },
      "source": [
        "## Install library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYtsa7XIE9OW",
        "outputId": "07335899-838a-41b6-be12-6179d781e878"
      },
      "source": [
        "# 0.0 Install attention\n",
        "! pip install attention"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: attention in /usr/local/lib/python3.7/dist-packages (4.0)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.7/dist-packages (from attention) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from attention) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.17.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1->attention) (0.6.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1->attention) (1.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1->attention) (4.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (4.2.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1->attention) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1->attention) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1->attention) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGbutE-pQNJu"
      },
      "source": [
        "## Call libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i17qhM9HFC9E"
      },
      "source": [
        "# 1.0 Usual libraries\n",
        "import numpy as np\n",
        "\n",
        "# 1.1 tensorflow related libraries\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from attention import Attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZxiYQ5Q9aP"
      },
      "source": [
        "# 1.2\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDsllxu7QUNf"
      },
      "source": [
        "### Generate some sample data\n",
        "Data has just one feature time-value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYHtd4TFPmw"
      },
      "source": [
        "# 2.0 Take past 10 time steps and make prediction for the next\n",
        "#       time step\n",
        "num_samples, time_steps, input_dim, output_dim = 100, 10, 8, 1\n",
        "data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
        "data_y = np.random.uniform(size=(num_samples, output_dim))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQ0XDMAFSR0",
        "outputId": "fcc6078f-6400-47e3-ce9a-81e11fbd7fd1"
      },
      "source": [
        "# 2.1 Observe data\n",
        "print(data_x.shape)\n",
        "print(data_x[:2])   # Show 2 sets of 10 time-steps each\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 10, 8)\n",
            "[[[7.02418148e-01 6.18682429e-01 2.24943995e-02 3.51913492e-01\n",
            "   2.10419469e-01 4.32435525e-01 7.35911030e-01 1.12899552e-03]\n",
            "  [9.45287137e-01 1.37788301e-01 1.10632684e-01 9.60056741e-01\n",
            "   5.55394142e-01 8.93564152e-01 6.13409198e-01 9.11303900e-01]\n",
            "  [2.89036619e-02 2.76187726e-02 8.74498411e-01 8.66868483e-01\n",
            "   3.76526354e-01 7.80368995e-01 4.03277796e-01 2.90274774e-01]\n",
            "  [3.20518444e-01 5.54589548e-02 8.83492761e-01 8.31341867e-01\n",
            "   7.98950945e-01 9.10382844e-01 7.23219942e-01 7.43439220e-01]\n",
            "  [7.23257934e-01 1.77441083e-01 8.60663525e-01 1.45703033e-02\n",
            "   7.38449596e-01 6.37138469e-01 8.60187639e-01 2.34251128e-01]\n",
            "  [5.75370300e-03 9.85433284e-02 9.94104370e-01 7.46644216e-01\n",
            "   9.56902276e-01 3.73078193e-01 8.19067979e-01 5.94479013e-01]\n",
            "  [2.09051774e-01 2.39954075e-02 7.52749014e-01 2.33582108e-01\n",
            "   6.94264667e-02 5.78445506e-01 8.11222450e-01 5.33884378e-01]\n",
            "  [8.19616666e-01 4.91226719e-01 4.79219635e-01 9.94039850e-01\n",
            "   4.18924638e-01 9.68194654e-01 6.33799723e-01 7.83833718e-01]\n",
            "  [2.52016830e-01 6.20454980e-01 9.55008497e-01 4.79552770e-04\n",
            "   4.12701146e-01 6.01451166e-01 5.73157995e-01 5.74500883e-01]\n",
            "  [7.84449825e-01 3.58018763e-01 2.08772182e-01 8.03190097e-01\n",
            "   7.93960289e-02 3.60554481e-01 4.67178498e-01 2.29112771e-01]]\n",
            "\n",
            " [[7.42632649e-01 4.05466924e-02 8.91095753e-02 2.38465209e-01\n",
            "   6.65365927e-01 6.35423404e-01 8.33755172e-01 9.57222183e-01]\n",
            "  [6.72973113e-01 5.52498835e-02 6.80362507e-01 4.60912310e-01\n",
            "   7.88481222e-01 2.77955790e-01 9.56887364e-01 7.31892859e-01]\n",
            "  [7.23539752e-01 5.11640732e-01 3.02798321e-01 6.18810770e-02\n",
            "   8.21826692e-02 8.23882597e-01 2.02775538e-01 8.26009873e-01]\n",
            "  [2.92066241e-01 9.65088241e-02 5.26070889e-01 8.19176940e-01\n",
            "   5.42491445e-01 4.58799695e-01 7.20751417e-01 5.06730045e-01]\n",
            "  [4.96579883e-01 9.56745990e-01 4.32137824e-01 8.35174183e-01\n",
            "   9.48690974e-01 8.59514304e-01 9.48368388e-01 5.46429523e-03]\n",
            "  [1.65180638e-01 9.94118880e-01 9.94456483e-01 1.15776242e-01\n",
            "   8.08744082e-01 9.70598450e-01 3.04306341e-01 3.68033892e-01]\n",
            "  [2.94658960e-01 9.83512462e-01 4.73998848e-02 1.02053260e-01\n",
            "   3.97764169e-02 1.43204514e-01 3.20268807e-02 7.47736488e-01]\n",
            "  [3.69534026e-01 9.44803892e-01 6.97817417e-01 2.59365583e-01\n",
            "   8.94982745e-01 4.02501432e-01 1.50267285e-01 8.77253440e-01]\n",
            "  [8.73320082e-01 3.83852385e-01 9.73889188e-01 2.70744920e-01\n",
            "   7.90336180e-01 5.40956718e-01 3.96629328e-01 3.20107352e-01]\n",
            "  [6.24834499e-01 3.60385509e-01 9.50664512e-01 2.22359448e-01\n",
            "   2.24305638e-02 2.59481079e-01 2.97020516e-01 8.69697607e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VV8nlF4TABG",
        "outputId": "a86ed411-dcbc-43d6-9773-83e4655013ce"
      },
      "source": [
        "# 2.2 Show next 4-values to be predicted\n",
        "print(data_y[:4])   # Show 4 values"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1525244 ]\n",
            " [0.64825146]\n",
            " [0.69913549]\n",
            " [0.96029106]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-gHr9LeWqcH"
      },
      "source": [
        "### Our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1XJGTlJF3tx"
      },
      "source": [
        "# 3.0 Define the model.\n",
        "model_input = Input(shape=(time_steps, input_dim))\n",
        "x = LSTM(64, return_sequences=True)(model_input)\n",
        "x = Attention(32)(x)\n",
        "x = Dense(1)(x)\n",
        "model = Model(model_input, x)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlO25nU6F6dX",
        "outputId": "ff0b2da0-8b24-43ad-b944-a26c491b6077"
      },
      "source": [
        "# 3.1 Compile and print model summary\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "print(model.summary())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 10, 8)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 10, 64)       18688       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last_hidden_state (Lambda)      (None, 64)           0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_score_vec (Dense)     (None, 10, 64)       4096        lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_score (Dot)           (None, 10)           0           last_hidden_state[0][0]          \n",
            "                                                                 attention_score_vec[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "attention_weight (Activation)   (None, 10)           0           attention_score[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "context_vector (Dot)            (None, 64)           0           lstm_2[0][0]                     \n",
            "                                                                 attention_weight[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_output (Concatenate)  (None, 128)          0           context_vector[0][0]             \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "attention_vector (Dense)        (None, 128)          16384       attention_output[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         attention_vector[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 39,297\n",
            "Trainable params: 39,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjAt8p9-GF2d",
        "outputId": "9e7a2ec2-0acc-4a99-9eb8-551053d02473"
      },
      "source": [
        "# 3.2 Start learning\n",
        "model.fit(data_x, data_y, epochs=10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 9ms/step - loss: 0.3425\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3361\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2528\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2729\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2649\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2498\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2508\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2476\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2547\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e2ab61750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIIKIYPTFHt4"
      },
      "source": [
        "# 3.3 Make predictions\n",
        "pred1 = model.predict(data_x)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaqmiFz0WxSY"
      },
      "source": [
        "### Save model for future"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZEzSG2ATxCi"
      },
      "source": [
        "# 4.0 Save model for future\n",
        "model.save('test_model.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsC6T5HGTy1d"
      },
      "source": [
        "# 4.1 Delete earlier model\n",
        "del model\n",
        "\n",
        "# 4.2 Load the saved model\n",
        "model_h5 = load_model('test_model.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l-ndoK3T7lK"
      },
      "source": [
        "# 4.3 Make predictions with the sabed model\n",
        "pred2 = model_h5.predict(data_x)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cHBmcN5T-tV",
        "outputId": "1322bc2f-f842-41a9-92d2-09420770dd44"
      },
      "source": [
        "# 4.4 Compare saved model predictions \n",
        "#      with predictions made before saving\n",
        "\n",
        "np.testing.assert_almost_equal(pred1, pred2)\n",
        "print('Success.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHsTno9XSDJ"
      },
      "source": [
        "########## I am done ###############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywns37NTGNWG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}